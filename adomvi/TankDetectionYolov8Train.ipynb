{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6324ebae-fbd4-4a30-ba85-2393a36496b8",
      "metadata": {
        "id": "6324ebae-fbd4-4a30-ba85-2393a36496b8"
      },
      "source": [
        "# Tank detection YoloV8 model train\n",
        "\n",
        "This notebook will train a [Yolov8](https://github.com/ultralytics/ultralytics) model for tank detection using publicly available annotated images of tanks.\n",
        "\n",
        "As the notebook will run the training with `PyTorch`, it is recommended to have GPUs available. If running in Google Colab, go to Edit > Notebook settings and select GPU hardware acceleration.\n",
        "\n",
        "The first step of the notebook will use [fiftyone](https://github.com/voxel51/fiftyone), to build a dataset of tank images and bounding box annotations for training the computer vision model. The tutorial notebook on [Fine-tuning YOLOv8 models for custom use cases](https://github.com/voxel51/fiftyone/blob/v0.21.0/docs/source/tutorials/yolov8.ipynb) is a usefull introduction on how to use `fiftyone`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "227f7e25-5ffc-4810-a28f-34b9b6929399",
      "metadata": {
        "id": "227f7e25-5ffc-4810-a28f-34b9b6929399"
      },
      "source": [
        "### Setup\n",
        "To get started, install FiftyOne and Ultralytics (Yolov8) and check PyTorch and GPU support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5e7ee439-d69e-4428-ae2d-522b24acd72f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e7ee439-d69e-4428-ae2d-522b24acd72f",
        "outputId": "c9cf18b6-8b7e-4df3-b31f-1e15b8276cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 2.0.1+cu118 (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "!pip install fiftyone ultralytics\n",
        "\n",
        "import torch\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55fd7685",
      "metadata": {
        "id": "55fd7685"
      },
      "source": [
        "We also setup some logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b4205b7c",
      "metadata": {
        "id": "b4205b7c"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "NOTEBOOK_DIR = os.path.abspath('')\n",
        "LOG = logging.getLogger()\n",
        "LOG.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ddff397",
      "metadata": {
        "id": "4ddff397"
      },
      "source": [
        "### Download images from ImageNet21k\n",
        "\n",
        "The first dataset we'll use is ImageNet21k. The ImageNet21k dataset is available at [https://image-net.org/download-images.php](https://image-net.org/download-images.php). You need to register and be granted access to download the images. We use the Winter 21 version since it gives the option of downloading the images for a single synset: https://image-net.org/data/winter21_whole/SYNSET_ID.tar, e.g., https://image-net.org/data/winter21_whole/n02352591.tar. The processed version of ImageNet21k is available here : https://github.com/Alibaba-MIIL/ImageNet21K. The classes ids and names are available here https://github.com/google-research/big_transfer/issues/7#issuecomment-640048775.\n",
        "\n",
        "We'll begin by downloading the classe names that are in ImageNet21k and look for relevant classes that we can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c038557c-7095-4350-89ee-19fb2dd12dff",
      "metadata": {
        "id": "c038557c-7095-4350-89ee-19fb2dd12dff"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def download_file(url: str, filename: Path) -> Path:\n",
        "    if filename.exists():\n",
        "        LOG.info(f'File {filename} already exists. Skipping download.')\n",
        "    else:\n",
        "        LOG.info(f'Downloading {filename} ...')\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            with open(filename, 'wb') as f:\n",
        "                shutil.copyfileobj(r.raw, f)\n",
        "        LOG.info('Download complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "35916971-4cc4-414e-9ccf-69dcbb600763",
      "metadata": {
        "id": "35916971-4cc4-414e-9ccf-69dcbb600763"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "def download_class_names() -> Dict[str, str]:\n",
        "    download_dir = Path(NOTEBOOK_DIR)\n",
        "    id_file = download_dir / 'imagenet21k_wordnet_ids.txt'\n",
        "    name_file = download_dir / 'imagenet21k_wordnet_lemmas.txt'\n",
        "\n",
        "    download_file('https://storage.googleapis.com/bit_models/imagenet21k_wordnet_ids.txt', id_file)\n",
        "    download_file('https://storage.googleapis.com/bit_models/imagenet21k_wordnet_lemmas.txt', name_file) \n",
        "         \n",
        "    with open(id_file, 'r') as f:\n",
        "        ids = f.readlines()\n",
        "\n",
        "    with open(name_file, 'r') as f:\n",
        "        names = f.readlines()\n",
        "\n",
        "    synsets = {ids[i].strip(): names[i].strip() for i in range(len(ids))}\n",
        "    return synsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "80abe59b-17cb-4632-bb5d-97cf5b6ef093",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80abe59b-17cb-4632-bb5d-97cf5b6ef093",
        "outputId": "3b1b735d-7fbe-4de7-91b9-79d4d5456af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Downloading /content/imagenet21k_wordnet_ids.txt ...\n",
            "INFO:root:Download complete.\n",
            "INFO:root:Downloading /content/imagenet21k_wordnet_lemmas.txt ...\n",
            "INFO:root:Download complete.\n"
          ]
        }
      ],
      "source": [
        "synsets = download_class_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d797ce22-b8a2-4a35-b399-2246285a1d44",
      "metadata": {
        "id": "d797ce22-b8a2-4a35-b399-2246285a1d44"
      },
      "source": [
        "We can now search the synsets for relevant keywords, i.e.\n",
        "\n",
        "- Lemma: **tank, army_tank, armored_combat_vehicle, armoured_combat_vehicle**; Class: n04389033\n",
        "- Lemma: **armored_personnel_carrier, armoured_personnel_carrier, APC**; Class: n02740300\n",
        "- Lemma: **armored_vehicle, armoured_vehicle**; Class: n02740533\n",
        "- Lemma: **tracked_vehicle**; Class: n04464852\n",
        "- Lemma: **military_vehicle**; Class: n03764276"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eec5c597-7a2f-4ab3-be0e-374ec36e8589",
      "metadata": {
        "id": "eec5c597-7a2f-4ab3-be0e-374ec36e8589"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def find_class_by_text(synsets, query):\n",
        "    for id, lemma in synsets.items():\n",
        "        if re.search(query, lemma, re.IGNORECASE):\n",
        "            print(f'Lemma: {lemma}; Class: {id}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "86424aee-41e1-4e29-b4ef-101e03f7331b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86424aee-41e1-4e29-b4ef-101e03f7331b",
        "outputId": "126a6182-c5b3-48cb-a907-713af7fa7df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma: armored_dinosaur; Class: n01701551\n",
            "Lemma: armored_scale; Class: n02249515\n",
            "Lemma: armored_catfish; Class: n02520525\n",
            "Lemma: armored_car, armoured_car; Class: n02739889\n",
            "Lemma: armored_car, armoured_car; Class: n02740061\n",
            "Lemma: armored_personnel_carrier, armoured_personnel_carrier, APC; Class: n02740300\n",
            "Lemma: armored_vehicle, armoured_vehicle; Class: n02740533\n",
            "Lemma: tank, army_tank, armored_combat_vehicle, armoured_combat_vehicle; Class: n04389033\n"
          ]
        }
      ],
      "source": [
        "find_class_by_text(synsets, 'armored')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "792f27b7-730a-40f3-964f-6f7b65835ff9",
      "metadata": {
        "id": "792f27b7-730a-40f3-964f-6f7b65835ff9"
      },
      "source": [
        "We can now download images and annotations for the relevant classes. The `download_imagenet_detections` function will download the images and annotations for the given synset ids **if the annotations exist** (not all classes have been annotated)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f2d34820-20d1-4f1a-ae8d-9f56e116e021",
      "metadata": {
        "id": "f2d34820-20d1-4f1a-ae8d-9f56e116e021"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "from typing import List\n",
        "\n",
        "def download_annotations(class_ids: List[str], dataset_dir: str) -> List[str]:\n",
        "    # Download zipfile with detections for all classes\n",
        "    dataset_path = Path(NOTEBOOK_DIR) / dataset_dir\n",
        "    annotations_file = dataset_path / \"bboxes_annotations.tar.gz\"\n",
        "    annotations_dir = dataset_path / \"bboxes_annotations\"\n",
        "    download_file('https://image-net.org/data/bboxes_annotations.tar.gz', annotations_file)\n",
        "\n",
        "    # Extract annotations\n",
        "    with tarfile.open(annotations_file, \"r:gz\") as tf:\n",
        "        tf.extractall(annotations_dir)\n",
        "\n",
        "    # Extract annotations for each class\n",
        "    annoted_classes = []\n",
        "    for class_id in class_ids:\n",
        "        class_label_dir = dataset_path / \"labels\" / class_id\n",
        "        if class_label_dir.exists():\n",
        "            LOG.info(f'Annotations directory {class_label_dir} already exists. Skipping extract.')\n",
        "        else:\n",
        "            annotations_class_file = annotations_dir / f\"{class_id}.tar.gz\"\n",
        "            if annotations_class_file.exists():\n",
        "                with tarfile.open(annotations_class_file, \"r:gz\") as tf:\n",
        "                    tf.extractall(annotations_dir)\n",
        "                shutil.move(annotations_dir / \"Annotation\" / class_id, class_label_dir)\n",
        "                LOG.info(f'Extracted annotations for {class_id} to {class_label_dir}')\n",
        "                annoted_classes.append(class_id)\n",
        "            else:\n",
        "                LOG.info(f'There are not annotations for class {class_id}.')\n",
        "\n",
        "    # Delete annotations directory\n",
        "    LOG.info('Deleting annotations dir.')\n",
        "    shutil.rmtree(annotations_dir)\n",
        "    return annoted_classes\n",
        "\n",
        "def download_imagenet_detections(class_ids: List[str], dataset_dir: str):\n",
        "    # Create dataset_dir\n",
        "    dataset_path = Path(NOTEBOOK_DIR) / dataset_dir\n",
        "    dataset_path.mkdir(exist_ok=True)\n",
        "    data_dir = dataset_path / \"data\"\n",
        "    data_dir.mkdir(exist_ok=True)\n",
        "    labels_dir = dataset_path / \"labels\"\n",
        "    labels_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    annoted_classes = download_annotations(class_ids, dataset_dir)\n",
        "\n",
        "    # Download synset images for each class with annotations\n",
        "    for class_id in annoted_classes:\n",
        "        class_dir = data_dir / class_id\n",
        "        if class_dir.exists():\n",
        "            LOG.info(f'Directory {class_dir} already exists. Skipping download.')\n",
        "        else:\n",
        "            tarfilename = dataset_path / f'{class_id}.tar'\n",
        "            url = f'https://image-net.org/data/winter21_whole/{class_id}.tar'\n",
        "            download_file(url, tarfilename)\n",
        "            with tarfile.open(tarfilename) as tf:\n",
        "                tf.extractall(class_dir)\n",
        "            LOG.info(f'Extracted {class_dir}.')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8ce556b7-e7a2-43cc-a90b-bf94cc1b2904",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ce556b7-e7a2-43cc-a90b-bf94cc1b2904",
        "outputId": "8d46bc2f-9096-4e9d-c2f2-4bb6967902ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Downloading /content/imagenet/bboxes_annotations.tar.gz ...\n",
            "INFO:root:Download complete.\n",
            "INFO:root:There are not annotations for class n02740300.\n",
            "INFO:root:Extracted annotations for n04389033 to /content/imagenet/labels/n04389033\n",
            "INFO:root:There are not annotations for class n02740533.\n",
            "INFO:root:There are not annotations for class n04464852.\n",
            "INFO:root:There are not annotations for class n03764276.\n",
            "INFO:root:Deleting annotations dir.\n",
            "INFO:root:Downloading /content/imagenet/n04389033.tar ...\n",
            "INFO:root:Download complete.\n",
            "INFO:root:Extracted /content/imagenet/data/n04389033.\n"
          ]
        }
      ],
      "source": [
        "dataset_dir = \"imagenet\"\n",
        "classes = [\"n02740300\", \"n04389033\", \"n02740533\", \"n04464852\", \"n03764276\"]\n",
        "download_imagenet_detections(classes, dataset_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a53bb08-acc9-4135-965d-fff947af49c1",
      "metadata": {
        "id": "4a53bb08-acc9-4135-965d-fff947af49c1"
      },
      "source": [
        "### Create a fiftyone dataset with the downloaded ImageNet data\n",
        "\n",
        "Now that we're downloaded images and annotations, we can create a fiftyone dataset to manage it. The first step is to remove labels which have no corresonding image, as this causes errors when importing the data into fiftyone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "83a377ae-e1be-406a-b66a-a870338b61ed",
      "metadata": {
        "id": "83a377ae-e1be-406a-b66a-a870338b61ed"
      },
      "outputs": [],
      "source": [
        "def cleanup_labels_without_images(dataset_dir: str):\n",
        "    dataset_path = Path(NOTEBOOK_DIR) / dataset_dir\n",
        "    data_dir = dataset_path / \"data\"\n",
        "    labels_dir = dataset_path / \"labels\"\n",
        "    classes = [path.name for path in data_dir.iterdir() if path.is_dir()]\n",
        "    for class_id in classes:\n",
        "        images = {path.stem for path in (data_dir / class_id).iterdir() if not path.is_dir()}\n",
        "        labels = {path.stem for path in (labels_dir / class_id).iterdir() if not path.is_dir()}\n",
        "        LOG.info(f'Deleting {len(labels.difference(images))} labels without images')\n",
        "        for label_id in labels.difference(images):\n",
        "            filename = labels_dir / class_id / (label_id + '.xml')\n",
        "            filename.unlink()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "01874e34-f2f7-48d4-bea7-fdce60c4332e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01874e34-f2f7-48d4-bea7-fdce60c4332e",
        "outputId": "d7b9283a-5119-4dde-9ef6-c0df83579b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Deleting 138 labels without images\n"
          ]
        }
      ],
      "source": [
        "cleanup_labels_without_images(dataset_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9105158",
      "metadata": {
        "id": "b9105158"
      },
      "source": [
        "We can now create a new dataset. Note that we set this dataset to be persistent, so you should use the `load_dataset('military-vehicles')` function to reload the dataset on ulterior runs of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5e318f62-02d8-4723-9024-a0db6b944da2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e318f62-02d8-4723-9024-a0db6b944da2",
        "outputId": "6f976904-795f-4b37-9cad-994fcfced222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Migrating database to v0.21.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.migrations.runner:Migrating database to v0.21.0\n",
            "INFO:httpx:HTTP Request: POST https://www.google-analytics.com/collect \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 378/378 [700.4ms elapsed, 0s remaining, 539.7 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 378/378 [700.4ms elapsed, 0s remaining, 539.7 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "import fiftyone as fo\n",
        "\n",
        "# Create the dataset\n",
        "dataset = fo.Dataset.from_dir(\n",
        "    dataset_dir=dataset_dir,\n",
        "    dataset_type=fo.types.VOCDetectionDataset,\n",
        ")\n",
        "\n",
        "\n",
        "dataset.name = \"military-vehicles\"\n",
        "dataset.persistent = True\n",
        "\n",
        "view = dataset.map_labels(\n",
        "    \"ground_truth\",\n",
        "    {\"n04389033\":\"tank\"}\n",
        ")\n",
        "view.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2d5254b2-c9a6-46ac-be48-3d7e70909427",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2d5254b2-c9a6-46ac-be48-3d7e70909427",
        "outputId": "c2d25c29-78eb-4da3-bb35-fcd9419d8162"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-84913867-95f7-4fa0-988c-de12e61f497b {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-84913867-95f7-4fa0-988c-de12e61f497b {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-84913867-95f7-4fa0-988c-de12e61f497b:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-84913867-95f7-4fa0-988c-de12e61f497b {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-84913867-95f7-4fa0-988c-de12e61f497b\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-84913867-95f7-4fa0-988c-de12e61f497b\">\n",
              "      <button id=\"foactivate-84913867-95f7-4fa0-988c-de12e61f497b\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Welcome to\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
            "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ïö‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ïë    ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
            "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù     ‚ñà‚ñà‚ïë     ‚ïö‚ñà‚ñà‚ïî‚ïù  ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù\n",
            "‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë        ‚ñà‚ñà‚ïë      ‚ñà‚ñà‚ïë   ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
            "‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù        ‚ïö‚ïê‚ïù      ‚ïö‚ïê‚ïù    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù v0.21.0\n",
            "\n",
            "If you're finding FiftyOne helpful, here's how you can get involved:\n",
            "\n",
            "|\n",
            "|  ‚≠ê‚≠ê‚≠ê Give the project a star on GitHub ‚≠ê‚≠ê‚≠ê\n",
            "|  https://github.com/voxel51/fiftyone\n",
            "|\n",
            "|  üöÄüöÄüöÄ Join the FiftyOne Slack community üöÄüöÄüöÄ\n",
            "|  https://slack.voxel51.com\n",
            "|\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.core.session.session:\n",
            "Welcome to\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
            "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ïö‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ïë    ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
            "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù     ‚ñà‚ñà‚ïë     ‚ïö‚ñà‚ñà‚ïî‚ïù  ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù\n",
            "‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë        ‚ñà‚ñà‚ïë      ‚ñà‚ñà‚ïë   ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
            "‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù        ‚ïö‚ïê‚ïù      ‚ïö‚ïê‚ïù    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù v0.21.0\n",
            "\n",
            "If you're finding FiftyOne helpful, here's how you can get involved:\n",
            "\n",
            "|\n",
            "|  ‚≠ê‚≠ê‚≠ê Give the project a star on GitHub ‚≠ê‚≠ê‚≠ê\n",
            "|  https://github.com/voxel51/fiftyone\n",
            "|\n",
            "|  üöÄüöÄüöÄ Join the FiftyOne Slack community üöÄüöÄüöÄ\n",
            "|  https://slack.voxel51.com\n",
            "|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "session = fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f07a55bb-f2c0-4220-8c42-2d57e8bbf192",
      "metadata": {
        "id": "f07a55bb-f2c0-4220-8c42-2d57e8bbf192"
      },
      "outputs": [],
      "source": [
        "session.freeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9d745b-9f41-4374-8710-895abe20ed68",
      "metadata": {
        "id": "5d9d745b-9f41-4374-8710-895abe20ed68"
      },
      "source": [
        "### Add OpenImage samples\n",
        "\n",
        "The ImageNet dataset only contained 378 annotated images of tanks, so we'll look into other available datasets to improve training of the model. We‚Äôll load [Open Images](https://storage.googleapis.com/openimages/web/index.html) samples with `Tank` detection labels, passing in `only_matching=True` to only load the `Tank` labels. We then map these labels by changing `Tank` into `tank`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9017bf53-1677-48ed-a9c1-a4c9155e8e4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9017bf53-1677-48ed-a9c1-a4c9155e8e4d",
        "outputId": "2e1f6506-14ec-424f-8230-6ec10e075171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/root/fiftyone/open-images-v7/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/open-images-v7/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/train/train-images-boxable-with-rotation.csv' to '/root/fiftyone/open-images-v7/train/metadata/image_ids.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/train/train-images-boxable-with-rotation.csv' to '/root/fiftyone/open-images-v7/train/metadata/image_ids.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|    4.8Gb/4.8Gb [3.2s elapsed, 0s remaining, 1.7Gb/s]         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|    4.8Gb/4.8Gb [3.2s elapsed, 0s remaining, 1.7Gb/s]         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/root/fiftyone/open-images-v7/train/metadata/classes.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/root/fiftyone/open-images-v7/train/metadata/classes.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmpahldi9er/metadata/hierarchy.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmpahldi9er/metadata/hierarchy.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v6/oidv6-train-annotations-bbox.csv' to '/root/fiftyone/open-images-v7/train/labels/detections.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v6/oidv6-train-annotations-bbox.csv' to '/root/fiftyone/open-images-v7/train/labels/detections.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1062 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 1062 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1062/1062 [1.3m elapsed, 0s remaining, 14.6 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1062/1062 [1.3m elapsed, 0s remaining, 14.6 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'test' to '/root/fiftyone/open-images-v7/test' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'test' to '/root/fiftyone/open-images-v7/test' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/test/test-images-with-rotation.csv' to '/root/fiftyone/open-images-v7/test/metadata/image_ids.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/test/test-images-with-rotation.csv' to '/root/fiftyone/open-images-v7/test/metadata/image_ids.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/root/fiftyone/open-images-v7/test/metadata/classes.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/root/fiftyone/open-images-v7/test/metadata/classes.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmpjnop09o6/metadata/hierarchy.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmpjnop09o6/metadata/hierarchy.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v5/test-annotations-bbox.csv' to '/root/fiftyone/open-images-v7/test/labels/detections.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v5/test-annotations-bbox.csv' to '/root/fiftyone/open-images-v7/test/labels/detections.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 134 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 134 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 134/134 [10.4s elapsed, 0s remaining, 13.9 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 134/134 [10.4s elapsed, 0s remaining, 13.9 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/open-images-v7/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/open-images-v7/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv' to '/root/fiftyone/open-images-v7/validation/metadata/image_ids.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv' to '/root/fiftyone/open-images-v7/validation/metadata/image_ids.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/root/fiftyone/open-images-v7/validation/metadata/classes.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/root/fiftyone/open-images-v7/validation/metadata/classes.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmpot6wxbc_/metadata/hierarchy.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmpot6wxbc_/metadata/hierarchy.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv' to '/root/fiftyone/open-images-v7/validation/labels/detections.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv' to '/root/fiftyone/open-images-v7/validation/labels/detections.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 50 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 50 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [3.7s elapsed, 0s remaining, 15.3 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [3.7s elapsed, 0s remaining, 15.3 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/open-images-v7/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/open-images-v7/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'open-images-v7' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'open-images-v7' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1062/1062 [2.6s elapsed, 0s remaining, 409.6 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1062/1062 [2.6s elapsed, 0s remaining, 409.6 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'open-images-v7' split 'test'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'open-images-v7' split 'test'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 134/134 [316.9ms elapsed, 0s remaining, 422.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 134/134 [316.9ms elapsed, 0s remaining, 422.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'open-images-v7' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'open-images-v7' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [116.8ms elapsed, 0s remaining, 459.8 samples/s]    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [116.8ms elapsed, 0s remaining, 459.8 samples/s]    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'open-images-v7' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'open-images-v7' created\n"
          ]
        }
      ],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "oi_samples = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    classes = [\"Tank\"],\n",
        "    only_matching=True,\n",
        "    label_types=\"detections\"\n",
        ").map_labels(\n",
        "    \"ground_truth\",\n",
        "    {\"Tank\":\"tank\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6686fed-39a4-417b-b38e-2925293d0a21",
      "metadata": {
        "id": "f6686fed-39a4-417b-b38e-2925293d0a21"
      },
      "source": [
        "We can add these new samples into our training dataset with `merge_samples()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4190b5f9-37c0-49c5-80c9-13660ca6264d",
      "metadata": {
        "id": "4190b5f9-37c0-49c5-80c9-13660ca6264d"
      },
      "outputs": [],
      "source": [
        "dataset.merge_samples(oi_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a3d74eb3-62e4-487a-819d-dc57473484c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "a3d74eb3-62e4-487a-819d-dc57473484c4",
        "outputId": "2d4632a1-eec4-454b-92ac-04448efe789e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-710f8135-5263-4f65-bbe5-1995ecaee7b6 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-710f8135-5263-4f65-bbe5-1995ecaee7b6 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-710f8135-5263-4f65-bbe5-1995ecaee7b6:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-710f8135-5263-4f65-bbe5-1995ecaee7b6 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-710f8135-5263-4f65-bbe5-1995ecaee7b6\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-710f8135-5263-4f65-bbe5-1995ecaee7b6\">\n",
              "      <button id=\"foactivate-710f8135-5263-4f65-bbe5-1995ecaee7b6\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "session = fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "30c884c1-b20b-433c-ae26-a8fab0232317",
      "metadata": {
        "id": "30c884c1-b20b-433c-ae26-a8fab0232317"
      },
      "outputs": [],
      "source": [
        "session.freeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset now contains 1624 annotated images of tanks."
      ],
      "metadata": {
        "id": "0xgspIpwntqf"
      },
      "id": "0xgspIpwntqf"
    },
    {
      "cell_type": "markdown",
      "id": "5dca0ed6-5e26-4de3-9910-2e491814ff7b",
      "metadata": {
        "id": "5dca0ed6-5e26-4de3-9910-2e491814ff7b"
      },
      "source": [
        "## Fine-tune a YOLOv8 detection model\n",
        "\n",
        "Now that our dataset is created, we'll export it into a format supported by YOLOv8 to train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2902ccd2-dcee-4325-b6fb-dbf7831dd6f9",
      "metadata": {
        "id": "2902ccd2-dcee-4325-b6fb-dbf7831dd6f9"
      },
      "outputs": [],
      "source": [
        "import fiftyone.utils.random as four\n",
        "\n",
        "# load dataset\n",
        "dataset = fo.load_dataset(\"military-vehicles\")\n",
        "\n",
        "## delete existing tags to start fresh\n",
        "dataset.untag_samples(dataset.distinct(\"tags\"))\n",
        "\n",
        "## split into train, test and val\n",
        "four.random_split(\n",
        "    dataset,\n",
        "    {\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae4756a-e1ed-4c86-bf08-63cf9b20dd70",
      "metadata": {
        "id": "0ae4756a-e1ed-4c86-bf08-63cf9b20dd70"
      },
      "source": [
        "The `export_yolo_data` function will export our dataset into the given directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d3554411-d495-4f4d-a31c-43d944d99e2e",
      "metadata": {
        "id": "d3554411-d495-4f4d-a31c-43d944d99e2e"
      },
      "outputs": [],
      "source": [
        "def export_yolo_data(\n",
        "    samples, \n",
        "    export_dir, \n",
        "    classes, \n",
        "    label_field = \"ground_truth\", \n",
        "    split = None\n",
        "    ):\n",
        "\n",
        "    if type(split) == list:\n",
        "        splits = split\n",
        "        for split in splits:\n",
        "            export_yolo_data(\n",
        "                samples, \n",
        "                export_dir, \n",
        "                classes, \n",
        "                label_field, \n",
        "                split\n",
        "            )   \n",
        "    else:\n",
        "        if split is None:\n",
        "            split_view = samples\n",
        "            split = \"val\"\n",
        "        else:\n",
        "            split_view = samples.match_tags(split)\n",
        "\n",
        "        split_view.export(\n",
        "            export_dir=export_dir,\n",
        "            dataset_type=fo.types.YOLOv5Dataset,\n",
        "            label_field=label_field,\n",
        "            classes=classes,\n",
        "            split=split\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0d48283c-b553-4064-bfc2-08bfd6f4d158",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d48283c-b553-4064-bfc2-08bfd6f4d158",
        "outputId": "faa99aa4-b35d-4847-954c-7e697fae98d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1299/1299 [6.2s elapsed, 0s remaining, 149.0 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1299/1299 [6.2s elapsed, 0s remaining, 149.0 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'vehicles' already exists; export will be merged with existing files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fiftyone.core.collections:Directory 'vehicles' already exists; export will be merged with existing files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163/163 [563.3ms elapsed, 0s remaining, 289.3 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163/163 [563.3ms elapsed, 0s remaining, 289.3 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'vehicles' already exists; export will be merged with existing files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fiftyone.core.collections:Directory 'vehicles' already exists; export will be merged with existing files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [532.4ms elapsed, 0s remaining, 304.3 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [532.4ms elapsed, 0s remaining, 304.3 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "## export in YOLO format\n",
        "export_yolo_data(\n",
        "    dataset, \n",
        "    \"vehicles\", \n",
        "    [\"tank\"], \n",
        "    split = [\"train\", \"val\", \"test\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b971b8f-a71b-4f42-98df-e2f4d3b0bcd5",
      "metadata": {
        "id": "5b971b8f-a71b-4f42-98df-e2f4d3b0bcd5"
      },
      "source": [
        "Now all that is left is to do the fine-tuning! We will use YOLO command line syntax, with mode=train. We will specify the initial weights as the starting point for training, the number of epochs, image size, and batch size.\n",
        "\n",
        "For this notebook, we use the `yolov8n.pt` (nano) model, which is the smallest, but larger models are available from ultralytics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e1d8c7-8c52-4750-a289-e764fa8b80ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15e1d8c7-8c52-4750-a289-e764fa8b80ee",
        "outputId": "cd8e66b7-f780-4553-df5c-d543917e072c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100% 6.23M/6.23M [00:00<00:00, 187MB/s]\n",
            "Ultralytics YOLOv8.0.115  Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=vehicles/dataset.yaml, epochs=60, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /tmp/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 48.0MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011043 parameters, 3011027 gradients\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/vehicles/labels/train... 1299 images, 0 backgrounds, 0 corrupt: 100% 1299/1299 [00:03<00:00, 373.28it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/vehicles/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/vehicles/labels/val... 163 images, 0 backgrounds, 0 corrupt: 100% 163/163 [00:00<00:00, 334.81it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/vehicles/labels/val.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/60      2.55G      1.091      1.791      1.451          6        640: 100% 82/82 [00:43<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.01it/s]\n",
            "                   all        163        210      0.526      0.455      0.453      0.236\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/60      2.32G      1.218      1.579      1.549         12        640: 100% 82/82 [00:39<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.13it/s]\n",
            "                   all        163        210      0.239      0.323      0.181     0.0846\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/60      2.34G      1.326       1.55      1.629          9        640: 100% 82/82 [00:38<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.89it/s]\n",
            "                   all        163        210      0.331      0.548      0.323      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/60       2.3G       1.31      1.505      1.618         25        640: 100% 82/82 [00:41<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.25it/s]\n",
            "                   all        163        210        0.8      0.652      0.722      0.325\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/60      2.32G      1.317      1.412      1.607         18        640: 100% 82/82 [00:39<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.24it/s]\n",
            "                   all        163        210      0.521      0.595       0.44      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/60      2.32G      1.268      1.344      1.574          7        640: 100% 82/82 [00:40<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.11it/s]\n",
            "                   all        163        210      0.646      0.581        0.6       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/60      2.32G      1.215       1.29      1.536         10        640: 100% 82/82 [00:39<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.26it/s]\n",
            "                   all        163        210      0.736      0.605      0.689      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/60      2.31G      1.188      1.246      1.507          8        640: 100% 82/82 [00:38<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.06it/s]\n",
            "                   all        163        210       0.67      0.688       0.68      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/60      2.29G      1.164      1.234      1.504         12        640: 100% 82/82 [00:38<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.22it/s]\n",
            "                   all        163        210      0.808       0.68      0.737      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/60      2.32G      1.151      1.226       1.49          5        640: 100% 82/82 [00:38<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.39it/s]\n",
            "                   all        163        210      0.788      0.648      0.756      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/60      2.33G      1.126      1.155      1.475         10        640: 100% 82/82 [00:39<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.45it/s]\n",
            "                   all        163        210      0.809      0.748      0.786      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/60      2.29G       1.11      1.133      1.479          6        640: 100% 82/82 [00:35<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.73it/s]\n",
            "                   all        163        210      0.732      0.714      0.763      0.455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/60      2.32G      1.099      1.121      1.452         11        640: 100% 82/82 [00:37<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.02it/s]\n",
            "                   all        163        210      0.781      0.667       0.77      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/60      2.33G      1.109      1.108       1.46         13        640: 100% 82/82 [00:38<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.74it/s]\n",
            "                   all        163        210       0.83      0.757      0.833      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/60      2.31G      1.058      1.056      1.424          6        640: 100% 82/82 [00:36<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.21it/s]\n",
            "                   all        163        210      0.834      0.771      0.834       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/60      2.32G      1.051      1.053      1.416         12        640: 100% 82/82 [00:37<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.93it/s]\n",
            "                   all        163        210      0.864      0.719      0.833      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/60       2.3G      1.026      1.015      1.387         12        640: 100% 82/82 [00:38<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.96it/s]\n",
            "                   all        163        210      0.792      0.762      0.811      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/60      2.34G      1.046      1.028      1.406          8        640: 100% 82/82 [00:37<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.33it/s]\n",
            "                   all        163        210      0.788      0.741       0.81      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/60      2.31G      1.014     0.9934       1.39         18        640: 100% 82/82 [00:36<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.10it/s]\n",
            "                   all        163        210       0.85      0.757      0.847      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/60      2.32G      1.026          1      1.394         14        640: 100% 82/82 [00:37<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.41it/s]\n",
            "                   all        163        210      0.802      0.748      0.822      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/60      2.31G     0.9857     0.9638      1.367         10        640: 100% 82/82 [00:37<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.17it/s]\n",
            "                   all        163        210      0.803      0.757      0.817      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/60      2.34G     0.9997     0.9675      1.385          9        640: 100% 82/82 [00:36<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.16it/s]\n",
            "                   all        163        210      0.777      0.798      0.859      0.565\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/60      2.32G     0.9654      0.958      1.353         17        640: 100% 82/82 [00:38<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.18it/s]\n",
            "                   all        163        210      0.854      0.754      0.837      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/60      2.32G     0.9606     0.9349      1.349         11        640: 100% 82/82 [00:37<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.21it/s]\n",
            "                   all        163        210      0.892      0.781      0.856      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/60      2.29G     0.9608     0.9137      1.353         12        640: 100% 82/82 [00:36<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.23it/s]\n",
            "                   all        163        210      0.892      0.786      0.868      0.595\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/60      2.31G     0.9623     0.9319      1.345          4        640: 100% 82/82 [00:37<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.39it/s]\n",
            "                   all        163        210      0.825      0.761      0.847      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/60      2.29G     0.9336     0.9131      1.334         10        640: 100% 82/82 [00:37<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.31it/s]\n",
            "                   all        163        210      0.867      0.779      0.854      0.583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/60      2.33G     0.9048     0.8823      1.307          7        640: 100% 82/82 [00:37<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.25it/s]\n",
            "                   all        163        210      0.896      0.767      0.851      0.595\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/60      2.29G     0.9246     0.8782      1.326          8        640: 100% 82/82 [00:39<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.23it/s]\n",
            "                   all        163        210      0.819      0.774      0.827      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/60       2.3G     0.9029     0.8642      1.307         12        640: 100% 82/82 [00:38<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.36it/s]\n",
            "                   all        163        210      0.872      0.712      0.835      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/60      2.31G     0.8874     0.8572      1.296         12        640: 100% 82/82 [00:36<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.06it/s]\n",
            "                   all        163        210      0.832      0.748      0.832      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/60      2.32G     0.8975     0.8547      1.298         12        640: 100% 82/82 [00:39<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.07it/s]\n",
            "                   all        163        210      0.896      0.776      0.862      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/60      2.31G      0.881     0.8204      1.297          6        640: 100% 82/82 [00:38<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "                   all        163        210      0.844      0.805      0.857      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/60      2.32G     0.8796     0.8165       1.29         10        640: 100% 82/82 [00:37<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.80it/s]\n",
            "                   all        163        210      0.798       0.79       0.83      0.568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/60      2.31G     0.8721     0.8144      1.291         12        640: 100% 82/82 [00:38<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.30it/s]\n",
            "                   all        163        210      0.869      0.825      0.878      0.632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/60      2.32G     0.8281     0.7964      1.259         11        640: 100% 82/82 [00:38<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.66it/s]\n",
            "                   all        163        210      0.877      0.814      0.861      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/60      2.32G     0.8294     0.7841      1.257         11        640: 100% 82/82 [00:37<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.78it/s]\n",
            "                   all        163        210      0.882      0.822      0.864      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/60       2.3G     0.8505     0.7867      1.267         13        640: 100% 82/82 [00:37<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.06it/s]\n",
            "                   all        163        210      0.876      0.795       0.87      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/60      2.32G     0.8285     0.7831       1.25         13        640: 100% 82/82 [00:40<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.07it/s]\n",
            "                   all        163        210      0.858       0.81      0.858      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/60      2.29G     0.8259     0.7655      1.248         24        640: 100% 82/82 [00:36<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.43it/s]\n",
            "                   all        163        210      0.824      0.781      0.821      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/60      2.31G     0.8005     0.7493      1.231          8        640: 100% 82/82 [00:37<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.12it/s]\n",
            "                   all        163        210      0.874      0.829      0.877      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/60      2.29G     0.8132     0.7439      1.238          9        640: 100% 82/82 [00:39<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.25it/s]\n",
            "                   all        163        210      0.807      0.834      0.839      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/60      2.29G     0.7842     0.7286      1.226         10        640: 100% 82/82 [00:36<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "                   all        163        210       0.89      0.833      0.871      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/60      2.32G     0.7887     0.7096      1.229         16        640: 100% 82/82 [00:37<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.26it/s]\n",
            "                   all        163        210      0.878       0.81      0.847       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/60      2.31G      0.773     0.7069      1.213          9        640: 100% 82/82 [00:39<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.09it/s]\n",
            "                   all        163        210      0.833       0.81      0.851      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/60      2.29G     0.7827     0.7085      1.217         12        640: 100% 82/82 [00:37<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.17it/s]\n",
            "                   all        163        210       0.91      0.795      0.862      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/60      2.31G     0.7542     0.6786        1.2          9        640: 100% 82/82 [00:36<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.19it/s]\n",
            "                   all        163        210      0.875      0.824      0.877      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/60      2.31G     0.7494     0.6738      1.196         10        640: 100% 82/82 [00:38<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.13it/s]\n",
            "                   all        163        210      0.835      0.819      0.848      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/60      2.29G     0.7426     0.6786      1.183          8        640: 100% 82/82 [00:37<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.30it/s]\n",
            "                   all        163        210      0.891      0.829      0.884      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/60      2.29G     0.7464     0.6602      1.195          8        640: 100% 82/82 [00:36<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.20it/s]\n",
            "                   all        163        210      0.911      0.781      0.869       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      51/60      2.31G     0.7285     0.6494      1.182         11        640: 100% 82/82 [00:38<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.96it/s]\n",
            "                   all        163        210      0.892      0.784      0.867      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      52/60      2.31G     0.7251     0.6301      1.184          9        640: 100% 82/82 [00:37<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "                   all        163        210      0.925      0.762      0.876      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      53/60      2.31G     0.7089      0.628       1.17          9        640: 100% 82/82 [00:37<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.26it/s]\n",
            "                   all        163        210      0.896      0.833      0.884      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      54/60      2.31G     0.6955     0.6255      1.159          8        640: 100% 82/82 [00:38<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.11it/s]\n",
            "                   all        163        210      0.832      0.857      0.884      0.648\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      55/60       2.3G     0.7006     0.6141      1.172         14        640: 100% 82/82 [00:38<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.48it/s]\n",
            "                   all        163        210      0.904      0.776      0.866      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      56/60      2.32G        0.7     0.6167      1.159          9        640: 100% 82/82 [00:36<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.04it/s]\n",
            "                   all        163        210      0.856      0.823      0.871      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      57/60      2.31G     0.6878     0.6127      1.161         11        640: 100% 82/82 [00:38<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.16it/s]\n",
            "                   all        163        210      0.884      0.833      0.866      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      58/60      2.32G     0.6813     0.5928      1.144         13        640: 100% 82/82 [00:38<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.44it/s]\n",
            "                   all        163        210      0.855      0.848      0.867      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      59/60      2.29G      0.675     0.5879      1.148         11        640: 100% 82/82 [00:36<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.07it/s]\n",
            "                   all        163        210      0.856       0.85      0.886      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      60/60      2.34G     0.6738     0.5907      1.149         14        640: 100% 82/82 [00:36<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:06<00:00,  1.05s/it]\n",
            "                   all        163        210      0.853      0.843      0.875      0.659\n",
            "\n",
            "60 epochs completed in 0.728 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.115  Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.12it/s]\n",
            "                   all        163        210      0.853      0.843      0.875      0.659\n",
            "Speed: 3.4ms preprocess, 4.1ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=train model=yolov8n.pt data=vehicles/dataset.yaml epochs=60 imgsz=640 batch=16"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JxRmqb8abzZ-",
      "metadata": {
        "id": "JxRmqb8abzZ-"
      },
      "source": [
        "Create a zip file with train results and download it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EDY1VtLccf6U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDY1VtLccf6U",
        "outputId": "11970c1a-a3f9-4026-ce82-87ea773d6083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/runs/detect/train/ (stored 0%)\n",
            "  adding: content/runs/detect/train/args.yaml (deflated 51%)\n",
            "  adding: content/runs/detect/train/results.png (deflated 7%)\n",
            "  adding: content/runs/detect/train/labels_correlogram.jpg (deflated 36%)\n",
            "  adding: content/runs/detect/train/train_batch0.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train/val_batch0_pred.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train/F1_curve.png (deflated 17%)\n",
            "  adding: content/runs/detect/train/confusion_matrix_normalized.png (deflated 38%)\n",
            "  adding: content/runs/detect/train/events.out.tfevents.1686316091.2a7eb5a7cbe9.9783.0 (deflated 72%)\n",
            "  adding: content/runs/detect/train/val_batch1_labels.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/train/results.csv (deflated 85%)\n",
            "  adding: content/runs/detect/train/confusion_matrix.png (deflated 39%)\n",
            "  adding: content/runs/detect/train/PR_curve.png (deflated 22%)\n",
            "  adding: content/runs/detect/train/val_batch0_labels.jpg (deflated 11%)\n",
            "  adding: content/runs/detect/train/train_batch2.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/train/P_curve.png (deflated 16%)\n",
            "  adding: content/runs/detect/train/val_batch1_pred.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/train/train_batch1.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/train/weights/best.pt (deflated 9%)\n",
            "  adding: content/runs/detect/train/weights/last.pt (deflated 9%)\n",
            "  adding: content/runs/detect/train/val_batch2_labels.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train/val_batch2_pred.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train/labels.jpg (deflated 23%)\n",
            "  adding: content/runs/detect/train/R_curve.png (deflated 17%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r yolov8_military.zip runs/detect/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HEpL25P5b3y_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "HEpL25P5b3y_",
        "outputId": "78f3ff77-fe41-402e-d913-888c884062ee"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f86a6b64-3a9e-4ffa-9f3a-d0261a51812b\", \"yolov8_military.zip\", 17134386)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/yolov8_military.zip') "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a0cc22-e87e-4d91-a520-5726c1d42629",
      "metadata": {
        "id": "83a0cc22-e87e-4d91-a520-5726c1d42629"
      },
      "source": [
        "With fine-tuning complete, we can generate predictions on our test data with the ‚Äúbest‚Äù weights found during the training process, which are stored at `runs/detect/train/weights/best.pt`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c27699-6a6d-482b-b52d-870aa93462e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94c27699-6a6d-482b-b52d-870aa93462e8",
        "outputId": "8b287d73-84da-4756-dc23-b9275da84ec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.115  Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Could not connect session, trying again in 10 seconds\n",
            "\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
            "\n",
            "image 1/162 /content/vehicles/images/test/0060fa461e2f119e.jpg: 448x640 2 tanks, 59.4ms\n",
            "image 2/162 /content/vehicles/images/test/007377a82dc87b7f.jpg: 448x640 2 tanks, 6.3ms\n",
            "image 3/162 /content/vehicles/images/test/011458ec5d8d61d8.jpg: 448x640 1 tank, 6.2ms\n",
            "image 4/162 /content/vehicles/images/test/01c1bff29e25b149.jpg: 320x640 2 tanks, 53.8ms\n",
            "image 5/162 /content/vehicles/images/test/01d94857a1fde861.jpg: 448x640 3 tanks, 6.7ms\n",
            "image 6/162 /content/vehicles/images/test/021bb7e1cbb12d26.jpg: 384x640 1 tank, 59.9ms\n",
            "image 7/162 /content/vehicles/images/test/03a3424b6d4591b6.jpg: 640x640 2 tanks, 7.9ms\n",
            "image 8/162 /content/vehicles/images/test/07a684cf90b5df0e.jpg: 480x640 2 tanks, 52.9ms\n",
            "image 9/162 /content/vehicles/images/test/07e79f408f1d4e90.jpg: 448x640 1 tank, 6.9ms\n",
            "image 10/162 /content/vehicles/images/test/0818e7009a2d2e04.jpg: 448x640 1 tank, 6.4ms\n",
            "image 11/162 /content/vehicles/images/test/08964a3d8754c1c4.jpg: 448x640 1 tank, 6.6ms\n",
            "image 12/162 /content/vehicles/images/test/0a342c215d3fc793.jpg: 480x640 3 tanks, 7.2ms\n",
            "image 13/162 /content/vehicles/images/test/0ada1ed384e4d879.jpg: 448x640 2 tanks, 7.5ms\n",
            "image 14/162 /content/vehicles/images/test/0af4d66572273aaf.jpg: 384x640 1 tank, 7.0ms\n",
            "image 15/162 /content/vehicles/images/test/0b4fd44b5c066dd3.jpg: 480x640 3 tanks, 7.9ms\n",
            "image 16/162 /content/vehicles/images/test/0bebe26b45959b0a.jpg: 480x640 1 tank, 6.6ms\n",
            "image 17/162 /content/vehicles/images/test/0caebf60a92a0170.jpg: 384x640 1 tank, 7.7ms\n",
            "image 18/162 /content/vehicles/images/test/0d7c5ed78b4821cf.jpg: 448x640 1 tank, 7.4ms\n",
            "image 19/162 /content/vehicles/images/test/0f3df6a31b052882.jpg: 480x640 2 tanks, 7.3ms\n",
            "image 20/162 /content/vehicles/images/test/100b567201d6cf95.jpg: 448x640 3 tanks, 7.3ms\n",
            "image 21/162 /content/vehicles/images/test/11eb6f4c68969afb.jpg: 384x640 1 tank, 7.6ms\n",
            "image 22/162 /content/vehicles/images/test/1566a94f7c44daf1.jpg: 480x640 1 tank, 7.3ms\n",
            "image 23/162 /content/vehicles/images/test/15e2ebc038cc5f0f.jpg: 448x640 2 tanks, 7.5ms\n",
            "image 24/162 /content/vehicles/images/test/167c41117f568e98.jpg: 416x640 1 tank, 58.1ms\n",
            "image 25/162 /content/vehicles/images/test/19542237554afa08.jpg: 480x640 1 tank, 7.9ms\n",
            "image 26/162 /content/vehicles/images/test/19cb3ecafce505c2.jpg: 448x640 1 tank, 7.3ms\n",
            "image 27/162 /content/vehicles/images/test/1ad4459e04737d6c.jpg: 480x640 2 tanks, 9.5ms\n",
            "image 28/162 /content/vehicles/images/test/1b909a9d6df05e3f.jpg: 640x480 1 tank, 59.6ms\n",
            "image 29/162 /content/vehicles/images/test/212993aa80881af1.jpg: 448x640 3 tanks, 7.6ms\n",
            "image 30/162 /content/vehicles/images/test/215982c57bd2a6a8.jpg: 480x640 1 tank, 10.8ms\n",
            "image 31/162 /content/vehicles/images/test/234650c23b640135.jpg: 448x640 2 tanks, 7.3ms\n",
            "image 32/162 /content/vehicles/images/test/23f901cb7e5a0246.jpg: 448x640 2 tanks, 7.0ms\n",
            "image 33/162 /content/vehicles/images/test/24ac44874456e1ac.jpg: 448x640 1 tank, 7.1ms\n",
            "image 34/162 /content/vehicles/images/test/26ee1b173a781f9b.jpg: 448x640 1 tank, 7.0ms\n",
            "image 35/162 /content/vehicles/images/test/2950384996921234.jpg: 448x640 3 tanks, 6.7ms\n",
            "image 36/162 /content/vehicles/images/test/2a5e4e7b882b2f6a.jpg: 448x640 1 tank, 7.4ms\n",
            "image 37/162 /content/vehicles/images/test/2c50097f3d617933.jpg: 480x640 1 tank, 7.7ms\n",
            "image 38/162 /content/vehicles/images/test/2e6e0a615a7c02a5.jpg: 448x640 3 tanks, 7.7ms\n",
            "image 39/162 /content/vehicles/images/test/2f144aeaf919c6d6.jpg: 480x640 6 tanks, 7.5ms\n",
            "image 40/162 /content/vehicles/images/test/319ece040b3987b4.jpg: 640x544 1 tank, 55.9ms\n",
            "image 41/162 /content/vehicles/images/test/3413efa4fc47b5ac.jpg: 480x640 1 tank, 7.2ms\n",
            "image 42/162 /content/vehicles/images/test/37d16473de9cc70d.jpg: 480x640 1 tank, 6.7ms\n",
            "image 43/162 /content/vehicles/images/test/38c811ce9ab74337.jpg: 448x640 2 tanks, 9.5ms\n",
            "image 44/162 /content/vehicles/images/test/3a66ef4929893c84.jpg: 480x640 2 tanks, 7.2ms\n",
            "image 45/162 /content/vehicles/images/test/3b07c8b7c607758b.jpg: 640x640 1 tank, 8.1ms\n",
            "image 46/162 /content/vehicles/images/test/3d73e9f589064a44.jpg: 480x640 2 tanks, 7.2ms\n",
            "image 47/162 /content/vehicles/images/test/3dc2968a6538f94a.jpg: 512x640 1 tank, 55.9ms\n",
            "image 48/162 /content/vehicles/images/test/46d0a576ba6ed593.jpg: 480x640 1 tank, 7.4ms\n",
            "image 49/162 /content/vehicles/images/test/4c43de2a07b8fa95.jpg: 448x640 1 tank, 7.2ms\n",
            "image 50/162 /content/vehicles/images/test/4c7dd323cc02e946.jpg: 448x640 1 tank, 6.6ms\n",
            "image 51/162 /content/vehicles/images/test/5103792c45f97a88.jpg: 448x640 1 tank, 6.8ms\n",
            "image 52/162 /content/vehicles/images/test/524a873b5b00b185.jpg: 448x640 1 tank, 6.6ms\n",
            "image 53/162 /content/vehicles/images/test/55138a9032e7c7d7.jpg: 480x640 1 tank, 6.9ms\n",
            "image 54/162 /content/vehicles/images/test/567031e1d7be3a7c.jpg: 448x640 2 tanks, 7.4ms\n",
            "image 55/162 /content/vehicles/images/test/58bae7c1eecf23b2.jpg: 384x640 1 tank, 7.5ms\n",
            "image 56/162 /content/vehicles/images/test/59efabf65be44195.jpg: 544x640 5 tanks, 51.6ms\n",
            "image 57/162 /content/vehicles/images/test/5cc630f885fce67c.jpg: 512x640 3 tanks, 7.3ms\n",
            "image 58/162 /content/vehicles/images/test/5ced211a95634eb0.jpg: 512x640 1 tank, 6.2ms\n",
            "image 59/162 /content/vehicles/images/test/5d279aaf1b840cf8.jpg: 448x640 3 tanks, 6.9ms\n",
            "image 60/162 /content/vehicles/images/test/5dab585320b5954f.jpg: 448x640 2 tanks, 6.2ms\n",
            "image 61/162 /content/vehicles/images/test/5f95320231007410.jpg: 480x640 1 tank, 7.3ms\n",
            "image 62/162 /content/vehicles/images/test/615e26933eb66c11.jpg: 480x640 1 tank, 6.3ms\n",
            "image 63/162 /content/vehicles/images/test/695f888964c4da6c.jpg: 480x640 1 tank, 6.3ms\n",
            "image 64/162 /content/vehicles/images/test/6d96c15cf01f0938.jpg: 448x640 2 tanks, 10.2ms\n",
            "image 65/162 /content/vehicles/images/test/6f9b1c96d8bedf9c.jpg: 480x640 1 tank, 6.9ms\n",
            "image 66/162 /content/vehicles/images/test/71b01293338c3c58.jpg: 640x448 1 tank, 54.8ms\n",
            "image 67/162 /content/vehicles/images/test/7860208cd6e7c759.jpg: 416x640 3 tanks, 6.9ms\n",
            "image 68/162 /content/vehicles/images/test/79555ee88785df4e.jpg: 640x448 1 tank, 6.7ms\n",
            "image 69/162 /content/vehicles/images/test/7c41c389d18c24e3.jpg: 480x640 1 tank, 6.7ms\n",
            "image 70/162 /content/vehicles/images/test/7d6a359edf71e138.jpg: 480x640 3 tanks, 9.2ms\n",
            "image 71/162 /content/vehicles/images/test/80cb2cfac3d0608e.jpg: 480x640 5 tanks, 6.1ms\n",
            "image 72/162 /content/vehicles/images/test/856f53386eb173f3.jpg: 448x640 4 tanks, 6.9ms\n",
            "image 73/162 /content/vehicles/images/test/883f9f53d39b7bef.jpg: 448x640 3 tanks, 7.8ms\n",
            "image 74/162 /content/vehicles/images/test/88f4864248fdded4.jpg: 480x640 2 tanks, 7.2ms\n",
            "image 75/162 /content/vehicles/images/test/8b3cc383c65d692e.jpg: 480x640 6 tanks, 6.9ms\n",
            "image 76/162 /content/vehicles/images/test/8c869aaca75a507a.jpg: 480x640 1 tank, 6.6ms\n",
            "image 77/162 /content/vehicles/images/test/8db139f2a21d7450.jpg: 480x640 2 tanks, 7.2ms\n",
            "image 78/162 /content/vehicles/images/test/8df6f6fcc04b6a06.jpg: 512x640 2 tanks, 7.2ms\n",
            "image 79/162 /content/vehicles/images/test/90424a253f09422d.jpg: 480x640 5 tanks, 7.0ms\n",
            "image 80/162 /content/vehicles/images/test/917114aa33bfa703.jpg: 448x640 1 tank, 7.8ms\n",
            "image 81/162 /content/vehicles/images/test/96079f31bac47e68.jpg: 448x640 1 tank, 7.2ms\n",
            "image 82/162 /content/vehicles/images/test/9711b402a52f8f22.jpg: 448x640 1 tank, 7.4ms\n",
            "image 83/162 /content/vehicles/images/test/9785c5a311b9fda9.jpg: 416x640 2 tanks, 7.1ms\n",
            "image 84/162 /content/vehicles/images/test/9d83c6317d7c1e23.jpg: 480x640 1 tank, 7.3ms\n",
            "image 85/162 /content/vehicles/images/test/9e9435737f1fc4cd.jpg: 448x640 2 tanks, 7.4ms\n",
            "image 86/162 /content/vehicles/images/test/a1b291e0338e4349.jpg: 640x480 1 tank, 8.6ms\n",
            "image 87/162 /content/vehicles/images/test/a1d2ecf8bd302c27.jpg: 480x640 1 tank, 7.5ms\n",
            "image 88/162 /content/vehicles/images/test/a2a7d1307f579d2b.jpg: 448x640 1 tank, 10.8ms\n",
            "image 89/162 /content/vehicles/images/test/a33847cc6b573c97.jpg: 480x640 2 tanks, 7.9ms\n",
            "image 90/162 /content/vehicles/images/test/a43e63b111bf1546.jpg: 448x640 1 tank, 7.8ms\n",
            "image 91/162 /content/vehicles/images/test/a541a346403683ff.jpg: 448x640 2 tanks, 6.8ms\n",
            "image 92/162 /content/vehicles/images/test/a9e709865b0a36f7.jpg: 448x640 1 tank, 7.4ms\n",
            "image 93/162 /content/vehicles/images/test/ab81bfcaa8526559.jpg: 416x640 2 tanks, 7.9ms\n",
            "image 94/162 /content/vehicles/images/test/ac1e64a99491f13c.jpg: 480x640 1 tank, 8.0ms\n",
            "image 95/162 /content/vehicles/images/test/af6f7af58edd9b00.jpg: 480x640 2 tanks, 6.6ms\n",
            "image 96/162 /content/vehicles/images/test/afc265574586405a.jpg: 448x640 1 tank, 6.9ms\n",
            "image 97/162 /content/vehicles/images/test/b6245d0b4e923667.jpg: 448x640 1 tank, 8.7ms\n",
            "image 98/162 /content/vehicles/images/test/b94f54ef50e25a67.jpg: 384x640 4 tanks, 8.2ms\n",
            "image 99/162 /content/vehicles/images/test/ba3c9e7fb2de1a4c.jpg: 448x640 2 tanks, 7.2ms\n",
            "image 100/162 /content/vehicles/images/test/ba72e37be9448f1e.jpg: 448x640 1 tank, 7.1ms\n",
            "image 101/162 /content/vehicles/images/test/bab9e1a3bb9c1be9.jpg: 448x640 2 tanks, 7.2ms\n",
            "image 102/162 /content/vehicles/images/test/bb7c516e9d7eeb7f.jpg: 448x640 1 tank, 7.2ms\n",
            "image 103/162 /content/vehicles/images/test/bc535df768d6eef9.jpg: 448x640 1 tank, 6.6ms\n",
            "image 104/162 /content/vehicles/images/test/bd62ac33927db95c.jpg: 448x640 3 tanks, 6.8ms\n",
            "image 105/162 /content/vehicles/images/test/bf42334f855b2771.jpg: 448x640 3 tanks, 6.8ms\n",
            "image 106/162 /content/vehicles/images/test/ce595bc657f52164.jpg: 448x640 2 tanks, 6.5ms\n",
            "image 107/162 /content/vehicles/images/test/dc751709d815e565.jpg: 448x640 2 tanks, 6.8ms\n",
            "image 108/162 /content/vehicles/images/test/dd5006c165e08b46.jpg: 480x640 1 tank, 7.0ms\n",
            "image 109/162 /content/vehicles/images/test/dd94f9d7fdad41b7.jpg: 448x640 1 tank, 11.3ms\n",
            "image 110/162 /content/vehicles/images/test/dddc86231692d5cc.jpg: 448x640 1 tank, 6.3ms\n",
            "image 111/162 /content/vehicles/images/test/de6c4a4ff9c9e17a.jpg: 416x640 1 tank, 9.9ms\n",
            "image 112/162 /content/vehicles/images/test/e34333ae8b0760dc.jpg: 448x640 1 tank, 7.4ms\n",
            "image 113/162 /content/vehicles/images/test/e8801aead8698e10.jpg: 640x512 1 tank, 57.7ms\n",
            "image 114/162 /content/vehicles/images/test/ed2c4449542711cb.jpg: 480x640 1 tank, 7.6ms\n",
            "image 115/162 /content/vehicles/images/test/f1aada6f3a0b7027.jpg: 448x640 3 tanks, 8.5ms\n",
            "image 116/162 /content/vehicles/images/test/f3ded5377f1f2298.jpg: 480x640 2 tanks, 7.6ms\n",
            "image 117/162 /content/vehicles/images/test/f7d64418696de09c.jpg: 448x640 1 tank, 8.0ms\n",
            "image 118/162 /content/vehicles/images/test/f8d393ad05bb2a1e.jpg: 480x640 2 tanks, 7.9ms\n",
            "image 119/162 /content/vehicles/images/test/f8eb0ee54fb3a201.jpg: 480x640 8 tanks, 7.0ms\n",
            "image 120/162 /content/vehicles/images/test/fd7d57338a2f0953.jpg: 512x640 1 tank, 7.5ms\n",
            "image 121/162 /content/vehicles/images/test/n04389033_10271.JPEG: 448x640 1 tank, 7.6ms\n",
            "image 122/162 /content/vehicles/images/test/n04389033_11108.JPEG: 512x640 1 tank, 7.1ms\n",
            "image 123/162 /content/vehicles/images/test/n04389033_12512.JPEG: 480x640 1 tank, 7.0ms\n",
            "image 124/162 /content/vehicles/images/test/n04389033_13050.JPEG: 480x640 1 tank, 8.6ms\n",
            "image 125/162 /content/vehicles/images/test/n04389033_13141.JPEG: 640x480 1 tank, 7.0ms\n",
            "image 126/162 /content/vehicles/images/test/n04389033_13491.JPEG: 448x640 1 tank, 8.2ms\n",
            "image 127/162 /content/vehicles/images/test/n04389033_13527.JPEG: 480x640 3 tanks, 7.2ms\n",
            "image 128/162 /content/vehicles/images/test/n04389033_14789.JPEG: 480x640 1 tank, 6.5ms\n",
            "image 129/162 /content/vehicles/images/test/n04389033_15378.JPEG: 480x640 1 tank, 6.3ms\n",
            "image 130/162 /content/vehicles/images/test/n04389033_1595.JPEG: 480x640 1 tank, 6.0ms\n",
            "image 131/162 /content/vehicles/images/test/n04389033_16581.JPEG: 320x640 1 tank, 6.8ms\n",
            "image 132/162 /content/vehicles/images/test/n04389033_1842.JPEG: 480x640 1 tank, 6.8ms\n",
            "image 133/162 /content/vehicles/images/test/n04389033_19259.JPEG: 480x640 1 tank, 6.2ms\n",
            "image 134/162 /content/vehicles/images/test/n04389033_19530.JPEG: 416x640 1 tank, 6.8ms\n",
            "image 135/162 /content/vehicles/images/test/n04389033_19879.JPEG: 480x640 1 tank, 7.3ms\n",
            "image 136/162 /content/vehicles/images/test/n04389033_2015.JPEG: 512x640 1 tank, 7.0ms\n",
            "image 137/162 /content/vehicles/images/test/n04389033_20412.JPEG: 448x640 1 tank, 7.0ms\n",
            "image 138/162 /content/vehicles/images/test/n04389033_23029.JPEG: 480x640 1 tank, 6.8ms\n",
            "image 139/162 /content/vehicles/images/test/n04389033_24385.JPEG: 480x640 1 tank, 6.1ms\n",
            "image 140/162 /content/vehicles/images/test/n04389033_2469.JPEG: 480x640 1 tank, 6.2ms\n",
            "image 141/162 /content/vehicles/images/test/n04389033_24738.JPEG: 480x640 5 tanks, 6.4ms\n",
            "image 142/162 /content/vehicles/images/test/n04389033_2557.JPEG: 480x640 2 tanks, 6.3ms\n",
            "image 143/162 /content/vehicles/images/test/n04389033_25719.JPEG: 448x640 1 tank, 6.6ms\n",
            "image 144/162 /content/vehicles/images/test/n04389033_26434.JPEG: 512x640 3 tanks, 8.8ms\n",
            "image 145/162 /content/vehicles/images/test/n04389033_27028.JPEG: 480x640 2 tanks, 7.0ms\n",
            "image 146/162 /content/vehicles/images/test/n04389033_29887.JPEG: 416x640 1 tank, 7.1ms\n",
            "image 147/162 /content/vehicles/images/test/n04389033_30632.JPEG: 448x640 1 tank, 9.2ms\n",
            "image 148/162 /content/vehicles/images/test/n04389033_30721.JPEG: 480x640 1 tank, 7.0ms\n",
            "image 149/162 /content/vehicles/images/test/n04389033_30990.JPEG: 480x640 5 tanks, 6.2ms\n",
            "image 150/162 /content/vehicles/images/test/n04389033_32488.JPEG: 480x640 1 tank, 7.2ms\n",
            "image 151/162 /content/vehicles/images/test/n04389033_425.JPEG: 480x640 2 tanks, 6.1ms\n",
            "image 152/162 /content/vehicles/images/test/n04389033_5200.JPEG: 384x640 1 tank, 7.0ms\n",
            "image 153/162 /content/vehicles/images/test/n04389033_5792.JPEG: 480x640 2 tanks, 6.7ms\n",
            "image 154/162 /content/vehicles/images/test/n04389033_622.JPEG: 448x640 1 tank, 7.3ms\n",
            "image 155/162 /content/vehicles/images/test/n04389033_6920.JPEG: 480x640 1 tank, 6.8ms\n",
            "image 156/162 /content/vehicles/images/test/n04389033_7113.JPEG: 480x640 3 tanks, 6.1ms\n",
            "image 157/162 /content/vehicles/images/test/n04389033_7506.JPEG: 640x512 1 tank, 6.9ms\n",
            "image 158/162 /content/vehicles/images/test/n04389033_8072.JPEG: 480x640 2 tanks, 6.7ms\n",
            "image 159/162 /content/vehicles/images/test/n04389033_8704.JPEG: 320x640 1 tank, 6.6ms\n",
            "image 160/162 /content/vehicles/images/test/n04389033_8821.JPEG: 448x640 (no detections), 6.6ms\n",
            "image 161/162 /content/vehicles/images/test/n04389033_9141.JPEG: 448x640 1 tank, 6.2ms\n",
            "image 162/162 /content/vehicles/images/test/n04389033_9428.JPEG: 544x640 1 tank, 7.7ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "161 labels saved to runs/detect/predict/labels\n",
            "\n",
            "Could not connect session, trying again in 10 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt source=vehicles/images/test save_txt=True save_conf=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M90XaKzvdEWT",
      "metadata": {
        "id": "M90XaKzvdEWT"
      },
      "outputs": [],
      "source": [
        "# The test split of the dataset\n",
        "test_view = dataset.match_tags(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Lscd1onDepQK",
      "metadata": {
        "id": "Lscd1onDepQK"
      },
      "source": [
        "### Load model detections"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GlgzpYb0etey",
      "metadata": {
        "id": "GlgzpYb0etey"
      },
      "source": [
        "We can read a YOLOv8 detection prediction file with $N$ detections into an $(N, 6)$ numpy array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kFWXcRgJeqcm",
      "metadata": {
        "id": "kFWXcRgJeqcm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def read_yolo_detections_file(filepath):\n",
        "    detections = []\n",
        "    if not os.path.exists(filepath):\n",
        "        return np.array([])\n",
        "    \n",
        "    with open(filepath) as f:\n",
        "        lines = [line.rstrip('\\n').split(' ') for line in f]\n",
        "    \n",
        "    for line in lines:\n",
        "        detection = [float(l) for l in line]\n",
        "        detections.append(detection)\n",
        "    return np.array(detections)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o-e2IUiHezBd",
      "metadata": {
        "id": "o-e2IUiHezBd"
      },
      "source": [
        "From here, we need to convert these detections into FiftyOne‚Äôs [Detections](https://docs.voxel51.com/user_guide/using_datasets.html#object-detection) format."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Trs-dnJle1io",
      "metadata": {
        "id": "Trs-dnJle1io"
      },
      "source": [
        "YOLOv8 represents bounding boxes in a centered format with coordinates `[center_x, center_y, width, height]`, whereas [FiftyOne stores bounding boxes](https://docs.voxel51.com/user_guide/using_datasets.html#object-detection) in `[top-left-x, top-left-y, width, height]` format. We can make this conversion by \"un-centering\" the predicted bounding boxes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p4Td_DXfewio",
      "metadata": {
        "id": "p4Td_DXfewio"
      },
      "outputs": [],
      "source": [
        "def _uncenter_boxes(boxes):\n",
        "    '''convert from center coords to corner coords'''\n",
        "    boxes[:, 0] -= boxes[:, 2]/2.\n",
        "    boxes[:, 1] -= boxes[:, 3]/2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JR9U3dNie73W",
      "metadata": {
        "id": "JR9U3dNie73W"
      },
      "source": [
        "Additionally, we can convert a list of class predictions (indices) to a list of class labels (strings) by passing in the class list:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LH1VC9lpe9_A",
      "metadata": {
        "id": "LH1VC9lpe9_A"
      },
      "outputs": [],
      "source": [
        "def _get_class_labels(predicted_classes, class_list):\n",
        "    labels = (predicted_classes).astype(int)\n",
        "    labels = [class_list[l] for l in labels]\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "V4H83IJFfBRK",
      "metadata": {
        "id": "V4H83IJFfBRK"
      },
      "source": [
        "Given the output of a `read_yolo_detections_file()` call, `yolo_detections`, we can generate the FiftyOne `Detections` object that captures this data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CAWkvy94e_dt",
      "metadata": {
        "id": "CAWkvy94e_dt"
      },
      "outputs": [],
      "source": [
        "def convert_yolo_detections_to_fiftyone(\n",
        "    yolo_detections, \n",
        "    class_list\n",
        "    ):\n",
        "\n",
        "    detections = []\n",
        "    if yolo_detections.size == 0:\n",
        "        return fo.Detections(detections=detections)\n",
        "    \n",
        "    boxes = yolo_detections[:, 1:-1]\n",
        "    _uncenter_boxes(boxes)\n",
        "    \n",
        "    confs = yolo_detections[:, -1]\n",
        "    labels = _get_class_labels(yolo_detections[:, 0], class_list) \n",
        " \n",
        "    for label, conf, box in zip(labels, confs, boxes):\n",
        "        detections.append(\n",
        "            fo.Detection(\n",
        "                label=label,\n",
        "                bounding_box=box.tolist(),\n",
        "                confidence=conf\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return fo.Detections(detections=detections)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XHPGnupgfGsE",
      "metadata": {
        "id": "XHPGnupgfGsE"
      },
      "source": [
        "The final ingredient is a function that takes in the file path of an image, and returns the file path of the corresponding YOLOv8 detection prediction text file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "puLw0q6sfEsZ",
      "metadata": {
        "id": "puLw0q6sfEsZ"
      },
      "outputs": [],
      "source": [
        "def get_prediction_filepath(filepath, run_number = 1):\n",
        "    run_num_string = \"\"\n",
        "    if run_number != 1:\n",
        "        run_num_string = str(run_number)\n",
        "    filename = filepath.split(\"/\")[-1].split(\".\")[0]\n",
        "    return f\"runs/detect/predict{run_num_string}/labels/{filename}.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NIzHbz1MfUoR",
      "metadata": {
        "id": "NIzHbz1MfUoR"
      },
      "source": [
        "If you run multiple inference calls for the same task, the predictions results are stored in a directory with the next available integer appended to `predict` in the file path. You can account for this in the above function by passing in the `run_number` argument.\n",
        "\n",
        "Putting the pieces together, we can write a function that adds these YOLOv8 detections to all of the samples in our dataset efficiently by batching the read and write operations to the underlying [MongoDB database](https://docs.voxel51.com/environments/index.html#connecting-to-a-localhost-database)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TSHGnEFtfLDU",
      "metadata": {
        "id": "TSHGnEFtfLDU"
      },
      "outputs": [],
      "source": [
        "def add_yolo_detections(\n",
        "    samples,\n",
        "    prediction_field,\n",
        "    prediction_filepath,\n",
        "    class_list\n",
        "    ):\n",
        "\n",
        "    prediction_filepaths = samples.values(prediction_filepath)\n",
        "    yolo_detections = [read_yolo_detections_file(pf) for pf in prediction_filepaths]\n",
        "    detections =  [convert_yolo_detections_to_fiftyone(yd, class_list) for yd in yolo_detections]\n",
        "    samples.set_values(prediction_field, detections)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3k-cGy48fbVR",
      "metadata": {
        "id": "3k-cGy48fbVR"
      },
      "source": [
        "Now we can rapidly add the detections in a few lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ENaQyWtNfYuw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENaQyWtNfYuw",
        "outputId": "70ed0fce-364f-4766-fa31-5a24af5463a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\n",
            "Could not connect session, trying again in 10 seconds\r\n",
            "\n"
          ]
        }
      ],
      "source": [
        "filepaths = test_view.values(\"filepath\")\n",
        "prediction_filepaths = [get_prediction_filepath(fp) for fp in filepaths]\n",
        "test_view.set_values(\n",
        "    \"yolov8n_det_filepath\", \n",
        "    prediction_filepaths\n",
        ")\n",
        "\n",
        "add_yolo_detections(\n",
        "    test_view, \n",
        "    \"yolov8n\", \n",
        "    \"yolov8n_det_filepath\", \n",
        "    [\"tank\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T14NB5WSf6pq",
      "metadata": {
        "id": "T14NB5WSf6pq"
      },
      "source": [
        "Now we can visualize these YOLOv8 model predictions on the samples in our dataset in the FiftyOne App:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "swpnpbTufnTT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "swpnpbTufnTT",
        "outputId": "050e172d-ad88-4cec-c427-5644b728a931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\n",
            "Could not connect session, trying again in 10 seconds\r\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-7e3e90b2-4e88-4fa4-8064-9b1c92d42cf8 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-7e3e90b2-4e88-4fa4-8064-9b1c92d42cf8 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-7e3e90b2-4e88-4fa4-8064-9b1c92d42cf8:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-7e3e90b2-4e88-4fa4-8064-9b1c92d42cf8 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-7e3e90b2-4e88-4fa4-8064-9b1c92d42cf8\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-7e3e90b2-4e88-4fa4-8064-9b1c92d42cf8\">\n",
              "      <button id=\"foactivate-7e3e90b2-4e88-4fa4-8064-9b1c92d42cf8\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "session = fo.launch_app(test_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KBc5bk_Uf8Lv",
      "metadata": {
        "id": "KBc5bk_Uf8Lv"
      },
      "outputs": [],
      "source": [
        "session.freeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XwzinvM4jzvL",
      "metadata": {
        "id": "XwzinvM4jzvL"
      },
      "source": [
        "### Evaluate model predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N-mIX-AvgRWo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-mIX-AvgRWo",
        "outputId": "687583fe-3a12-47f1-ccdb-7975a1dab73c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating detections...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.eval.detection:Evaluating detections...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [708.1ms elapsed, 0s remaining, 228.8 samples/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [708.1ms elapsed, 0s remaining, 228.8 samples/s]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing IoU sweep...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.eval.coco:Performing IoU sweep...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [819.9ms elapsed, 0s remaining, 197.6 samples/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [819.9ms elapsed, 0s remaining, 197.6 samples/s]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\n",
            "Could not connect session, trying again in 10 seconds\r\n",
            "\n"
          ]
        }
      ],
      "source": [
        "detection_results = test_view.evaluate_detections(\n",
        "    \"yolov8n\", \n",
        "    eval_key=\"eval\",\n",
        "    compute_mAP=True,\n",
        "    gt_field=\"ground_truth\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nizpHWoAkCza",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nizpHWoAkCza",
        "outputId": "ba91d114-049a-423b-9984-d9e08d1e89ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mAP = 0.4973578627422652\n"
          ]
        }
      ],
      "source": [
        "mAP = detection_results.mAP()\n",
        "print(f\"mAP = {mAP}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R55j6_mTkGZv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R55j6_mTkGZv",
        "outputId": "87ae6b99-13e6-4225-dee2-466686abbff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        tank       0.66      0.74      0.70       249\n",
            "\n",
            "   micro avg       0.66      0.74      0.70       249\n",
            "   macro avg       0.66      0.74      0.70       249\n",
            "weighted avg       0.66      0.74      0.70       249\n",
            "\n"
          ]
        }
      ],
      "source": [
        "detection_results.print_report()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2LK4iyCjkc7_",
      "metadata": {
        "id": "2LK4iyCjkc7_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
