{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16172d3-4aaf-4b8d-b9e1-b67f8322e01d",
   "metadata": {},
   "source": [
    "# Fine-tune a YOLOv8 detection model\n",
    "\n",
    "This notebook will train a [Yolov8](https://github.com/ultralytics/ultralytics) model for tank detection using publicly available annotated images of tanks.\n",
    "\n",
    "As the notebook will run the training with `PyTorch`, it is recommended to have GPUs available. If running in Google Colab, go to Edit > Notebook settings and select GPU hardware acceleration.\n",
    "\n",
    "This notebook expects that the dataset created in the notebook [01_Dataset](./01_Dataset.ipynb) has been saved to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d75f09-636f-4786-9d60-4a672c41c055",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49a9fd6-7e7e-4f53-b0b0-63b76935b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78070ae-5cde-47ef-a394-4cbd74ad3cf7",
   "metadata": {},
   "source": [
    "To start, check GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc4c32f-48a1-453a-8526-63f79f504b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 2.3.0+cu121 (NVIDIA RTX A6000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15382b1e-27bb-4614-b6e2-431ec0dd4967",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef8e715-e340-4187-a130-7c908114dd53",
   "metadata": {},
   "source": [
    "We'll first load the dataset created on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed58948a-0722-4abe-8bef-455309e652af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path() / \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031dba9b-53d3-4d09-8c4d-21f4cf15aca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1299/1299 [1.1s elapsed, 0s remaining, 1.2K samples/s]         \n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [131.0ms elapsed, 0s remaining, 1.3K samples/s]     \n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 162/162 [138.3ms elapsed, 0s remaining, 1.2K samples/s]     \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# The splits to load\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Load the dataset, using tags to mark the samples in each split\n",
    "dataset = fo.Dataset()\n",
    "for split in splits:\n",
    "    dataset.add_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        tags=split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec0a8e5-e73f-4ea3-b430-a0685292befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to FiftyOne on port 5151 at localhost.\n",
      "If you are not connecting to a remote session, you may need to start a new session and specify a port\n",
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(dataset, auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32557b80-147f-4628-963e-b0b4c41342f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.open('http://localhost:5151/');"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0513e-7034-4949-b2f7-07423bfdfaca",
   "metadata": {},
   "source": [
    "### Train a YoloV8 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c987c05-848b-439e-8705-0735b100180f",
   "metadata": {},
   "source": [
    "We can now train a YoloV8 base model on our exported dataset. We use the `yolov8n.pt` (nano) model, which is the smallest, but larger models are available from ultralytics. Simply replace `yolov8n.pt` with the [right model](https://docs.ultralytics.com/models/yolov8/#key-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6999159-b029-4cd7-97ed-68b40311cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.7M/49.7M [00:04<00:00, 11.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.30 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.14 torch-2.3.0+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                            CUDA:1 (NVIDIA RTX A6000, 48655MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=dataset/dataset.yaml, epochs=60, time=None, patience=100, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=[0, 1], workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /home/ukemkata/miniconda3/envs/adomvi2/bin/python -m torch.distributed.run --nproc_per_node 2 --master_port 46517 /home/ukemkata/.config/Ultralytics/DDP/_temp_w8fy8ax1140646780855216.py\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.14 torch-2.3.0+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                            CUDA:1 (NVIDIA RTX A6000, 48655MiB)\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 11.5MB/s]\n",
      "/home/ukemkata/miniconda3/envs/adomvi2/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ukemkata/workspace/adomvi2/notebooks/dataset/labels/train... 1299 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1299/1299 [00:01<00:00, 973.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/ukemkata/workspace/adomvi2/notebooks/dataset/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ukemkata/workspace/adomvi2/notebooks/dataset/labels/val... 163 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [00:00<00:00, 1282.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/ukemkata/workspace/adomvi2/notebooks/dataset/labels/val.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 16 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/60      13.4G     0.9702      1.957      1.394         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:08<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.55it/s]/home/ukemkata/miniconda3/envs/adomvi2/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.738      0.651      0.695      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/60      13.5G     0.8376       1.05      1.306         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238       0.73      0.609      0.581      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/60      13.5G      0.931       1.03      1.345         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.683      0.605      0.606      0.304\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/60      13.5G       1.02      1.089      1.425         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.244      0.534      0.306      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/60      13.5G      1.139      1.185      1.507         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.216      0.387      0.151     0.0449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/60      13.5G      1.138       1.16      1.533         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238     0.0721      0.248     0.0486     0.0181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/60      13.6G      1.138      1.169      1.519         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.203      0.356      0.173     0.0703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/60      13.5G      1.057       1.11      1.465         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.399        0.5      0.365      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/60      13.5G      1.058       1.08      1.452         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.728      0.676       0.68       0.37\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/60      13.6G      1.054      1.028      1.445         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.688       0.71        0.7      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/60      13.5G       1.03      1.013      1.448         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.727      0.723      0.753      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/60      13.6G     0.9925     0.9484      1.398         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.761      0.685      0.737      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/60      13.5G     0.9578     0.9119      1.383         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.817      0.676      0.758      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/60      13.5G      0.925      0.916      1.343         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.817      0.712      0.767      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/60      13.5G     0.9041     0.8457       1.34         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238       0.81      0.756       0.82      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/60      13.6G     0.9084     0.8309       1.32         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.885       0.71      0.819      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/60      13.5G     0.8975     0.8511       1.32         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.875      0.703      0.813      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/60      13.5G     0.9115     0.8332      1.335         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.803      0.718      0.787      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/60      13.5G     0.8669     0.8222      1.312         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.847      0.739      0.822      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/60      13.6G     0.8362     0.8005       1.29         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  3.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.895       0.72      0.835      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/60      13.5G     0.8173     0.7601      1.268         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.846      0.803      0.862      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/60      13.5G     0.8024     0.7208       1.25         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.877      0.723      0.836      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/60      13.5G     0.7991     0.7284      1.254         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.884      0.772      0.863      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/60      13.6G     0.8029     0.7356      1.269         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  3.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.843      0.777      0.849        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/60      13.5G     0.7624     0.6871      1.229         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.816      0.811      0.861       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/60      13.5G     0.7387     0.6586      1.217         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.855      0.735      0.854      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/60      13.5G     0.7718     0.6818      1.231         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.875      0.744      0.821      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/60      13.6G     0.7474     0.6678      1.217         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.906       0.73      0.862       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/60      13.5G     0.7183     0.6408      1.208         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.859      0.818      0.875      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/60      13.5G     0.7121     0.6283      1.194         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.936      0.733      0.868      0.618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/60      13.5G     0.7018     0.6321      1.181         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.914      0.763      0.858      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/60      13.5G     0.6865     0.6192      1.165         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.898      0.777      0.878      0.638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/60      13.5G      0.644     0.5803      1.141         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.831      0.773      0.868      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/60      13.6G     0.6652      0.587      1.163         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.906      0.761      0.843      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/60      13.6G     0.6662     0.5706      1.148         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.861      0.727      0.808      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/60      13.5G     0.6615     0.5586      1.142         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238       0.89      0.786      0.865      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/60      13.6G     0.6299     0.5191      1.132         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.863      0.794      0.862      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/60      13.5G     0.6502     0.5517      1.165         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.879      0.761      0.851      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/60      13.5G     0.6369     0.5203      1.156         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238       0.92      0.768      0.863      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/60      13.5G     0.6207     0.5233      1.126         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.881      0.809      0.884      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/60      13.5G      0.594     0.5019      1.109         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.902      0.807      0.891      0.643\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/60      13.5G     0.6209     0.4991      1.127         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.867      0.824      0.892      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/60      13.6G     0.5825     0.4796      1.094         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.895      0.777      0.881      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/60      13.6G     0.5686      0.475      1.111         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.844      0.861        0.9      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/60      13.5G     0.5545     0.4497      1.084         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.899      0.798      0.901      0.638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/60      13.5G     0.5453     0.4557      1.088         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.926      0.786       0.89      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/60      13.5G     0.5756      0.464      1.108         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.872      0.803      0.883      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/60      13.5G     0.5397     0.4332      1.068         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.892      0.777      0.884      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/60      13.5G     0.5271      0.421      1.066         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238        0.9      0.765      0.872      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/60      13.6G     0.5255      0.432      1.069         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.915      0.771      0.879      0.662\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      51/60      13.5G     0.4696     0.3687      1.023         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.907      0.769      0.876      0.673\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      52/60      13.5G     0.4268     0.3228     0.9847         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238       0.91      0.782      0.875      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      53/60      13.5G     0.3946     0.2902      0.962         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238       0.92      0.761      0.871      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      54/60      13.5G     0.4028     0.2891     0.9782         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238       0.92      0.772      0.868      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      55/60      13.5G     0.3874     0.2679     0.9399         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.936      0.752      0.869      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      56/60      13.5G     0.3871     0.2703     0.9356         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.942      0.765      0.874      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      57/60      13.5G     0.3572     0.2537     0.9362         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.907      0.778       0.88      0.671\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      58/60      13.5G      0.347     0.2403     0.9413         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.915       0.79      0.883      0.671\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      59/60      13.5G     0.3443      0.242     0.9306         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.933       0.79      0.884      0.672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      60/60      13.5G     0.3476      0.239     0.9327         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.933      0.794      0.888      0.671\n",
      "\n",
      "60 epochs completed in 0.142 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.14 torch-2.3.0+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                            CUDA:1 (NVIDIA RTX A6000, 48655MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ukemkata/miniconda3/envs/adomvi2/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        163        238      0.907      0.769      0.876      0.672\n",
      "Speed: 0.1ms preprocess, 2.5ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from adomvi.yolo.yolo import train\n",
    "\n",
    "train(\"yolov8m.pt\", data=dataset_dir / \"dataset.yaml\", batch=64, device=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93614090-c4ea-4121-8e85-b85c5d49bec5",
   "metadata": {},
   "source": [
    "### Use the fine-tuned model to predict detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d024f-a83a-490f-80ff-020165dc8231",
   "metadata": {},
   "source": [
    "Once our model is trained, we can simply use it to predict detections on our test dataset. Simply pass the path to the best model weights and the directory containing the test images to the `predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712aefbd-757a-4184-8de6-4203a517f794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/021bb7e1cbb12d26.jpg: 384x640 1 tank, 89.2ms\n",
      "image 2/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/02766a4a2a22632b.jpg: 640x448 1 tank, 89.4ms\n",
      "image 3/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/030eab769f338ba7.jpg: 352x640 1 tank, 89.2ms\n",
      "image 4/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/046bb8fe53b32324.jpg: 448x640 2 tanks, 89.2ms\n",
      "image 5/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/067371b2633fef26.jpg: 480x640 3 tanks, 93.5ms\n",
      "image 6/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/06792ed46d1efc53.jpg: 480x640 1 tank, 5.0ms\n",
      "image 7/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/06feff921dac9884.jpg: 448x640 1 tank, 5.2ms\n",
      "image 8/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/08794752f8f40af8.jpg: 448x640 1 tank, 4.7ms\n",
      "image 9/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/092738a560ad6c76.jpg: 448x640 3 tanks, 4.7ms\n",
      "image 10/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/099169acb6e8b3c8.jpg: 640x416 6 tanks, 88.8ms\n",
      "image 11/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/0afd8fb94705a2a6.jpg: 448x640 3 tanks, 5.4ms\n",
      "image 12/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/0bb732b73da86f35.jpg: 416x640 2 tanks, 87.6ms\n",
      "image 13/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/0cab44cde9def954.jpg: 448x640 1 tank, 5.3ms\n",
      "image 14/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/0d7c5ed78b4821cf.jpg: 448x640 1 tank, 4.8ms\n",
      "image 15/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/10be5edf863db0c1.jpg: 256x640 3 tanks, 89.0ms\n",
      "image 16/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/119d88cceb25d0d8.jpg: 448x640 2 tanks, 5.5ms\n",
      "image 17/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/11abde108502a9c7.jpg: 448x640 4 tanks, 4.8ms\n",
      "image 18/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/11ac383ce8f25496.jpg: 448x640 1 tank, 5.0ms\n",
      "image 19/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/12c618097b407cd0.jpg: 448x640 1 tank, 5.0ms\n",
      "image 20/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/15162977a524859b.jpg: 480x640 1 tank, 5.4ms\n",
      "image 21/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/169782b5ea61e3a9.jpg: 448x640 2 tanks, 5.2ms\n",
      "image 22/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/16f56c4e4a7da4f3.jpg: 448x640 2 tanks, 4.7ms\n",
      "image 23/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/183f600e458397cc.jpg: 448x640 1 tank, 4.7ms\n",
      "image 24/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/187cff1175259b10.jpg: 480x640 1 tank, 5.1ms\n",
      "image 25/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/1c1b752401588b0b.jpg: 448x640 1 tank, 5.2ms\n",
      "image 26/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/1e979696da9ccd5e.jpg: 448x640 1 tank, 4.8ms\n",
      "image 27/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/20b5aee9331a949c.jpg: 448x640 1 tank, 4.7ms\n",
      "image 28/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/2376326bd18a54c5.jpg: 448x640 1 tank, 4.6ms\n",
      "image 29/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/24911097e4761cdc.jpg: 448x640 1 tank, 4.9ms\n",
      "image 30/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/30403490e5259620.jpg: 448x640 1 tank, 4.6ms\n",
      "image 31/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/346d9418033fc60f.jpg: 448x640 1 tank, 4.7ms\n",
      "image 32/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/3a3a34376fc8ea18.jpg: 480x640 1 tank, 5.1ms\n",
      "image 33/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/3b07c8b7c607758b.jpg: 640x640 1 tank, 5.8ms\n",
      "image 34/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/3b2b74ce9fe6a438.jpg: 640x448 1 tank, 5.2ms\n",
      "image 35/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/3eee137586a92d2a.jpg: 480x640 1 tank, 9.9ms\n",
      "image 36/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/40364079c69e1dbb.jpg: 480x640 1 tank, 5.1ms\n",
      "image 37/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/4050f03f06399675.jpg: 448x640 1 tank, 5.3ms\n",
      "image 38/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/455a06159c57874b.jpg: 480x640 1 tank, 5.5ms\n",
      "image 39/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/47baa2ab9325b56a.jpg: 640x448 2 tanks, 5.3ms\n",
      "image 40/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/4bf44137f0f3c26a.jpg: 480x640 1 tank, 5.3ms\n",
      "image 41/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/4c43de2a07b8fa95.jpg: 448x640 1 tank, 5.3ms\n",
      "image 42/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/4d1863e8b7e5afa8.jpg: 480x640 4 tanks, 11.5ms\n",
      "image 43/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/4f382d56f4fce2af.jpg: 448x640 1 tank, 5.7ms\n",
      "image 44/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/505637dc93bbaef1.jpg: 448x640 1 tank, 5.0ms\n",
      "image 45/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/50e2c8c62470c6f5.jpg: 448x640 1 tank, 4.9ms\n",
      "image 46/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/51439bb53dfa97b3.jpg: 480x640 (no detections), 5.4ms\n",
      "image 47/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/5512787f74b2d996.jpg: 512x640 1 tank, 111.4ms\n",
      "image 48/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/5568baffb6280b92.jpg: 480x640 3 tanks, 5.6ms\n",
      "image 49/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/55bdf9f4bf991e9d.jpg: 448x640 2 tanks, 5.4ms\n",
      "image 50/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/573734c966bdf3a4.jpg: 352x640 2 tanks, 5.3ms\n",
      "image 51/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/5755759be6b7b542.jpg: 384x640 1 tank, 5.3ms\n",
      "image 52/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/5ee465c65eee633f.jpg: 448x640 1 tank, 5.1ms\n",
      "image 53/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/61945903dab27d9e.jpg: 320x640 1 tank, 88.5ms\n",
      "image 54/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/63e86e3144157862.jpg: 480x640 1 tank, 5.5ms\n",
      "image 55/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/649cfb09294de194.jpg: 512x640 1 tank, 5.5ms\n",
      "image 56/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/66d83317479d553b.jpg: 448x640 2 tanks, 5.2ms\n",
      "image 57/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/68e2ec9956e03397.jpg: 480x640 1 tank, 5.2ms\n",
      "image 58/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/6d9589c12e5ee333.jpg: 480x640 1 tank, 4.9ms\n",
      "image 59/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/6ea24c394ade99cb.jpg: 448x640 2 tanks, 5.2ms\n",
      "image 60/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/76ced4530257b1bd.jpg: 480x640 2 tanks, 5.3ms\n",
      "image 61/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/771d68a7ed1f44d7.jpg: 448x640 1 tank, 7.6ms\n",
      "image 62/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/7768ca8b619ee703.jpg: 544x640 1 tank, 88.5ms\n",
      "image 63/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/79555ee88785df4e.jpg: 640x448 1 tank, 5.6ms\n",
      "image 64/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/7dd4d76cf73b0891.jpg: 384x640 1 tank, 5.4ms\n",
      "image 65/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/87707a7cb814cb2e.jpg: 448x640 1 tank, 5.1ms\n",
      "image 66/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/89af4c3b887beb5a.jpg: 448x640 1 tank, 5.0ms\n",
      "image 67/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/8b10a4896215d56e.jpg: 512x640 1 tank, 5.3ms\n",
      "image 68/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/8b4945dd444b7dc9.jpg: 640x480 1 tank, 86.3ms\n",
      "image 69/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/8c68f5c50da82b1b.jpg: 544x640 1 tank, 5.2ms\n",
      "image 70/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/8c76dd551b6616e3.jpg: 448x640 4 tanks, 5.2ms\n",
      "image 71/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/93d1f18ff8497c48.jpg: 448x640 1 tank, 4.8ms\n",
      "image 72/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/9652539c702711cc.jpg: 480x640 1 tank, 5.3ms\n",
      "image 73/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/96c62798db147da6.jpg: 480x640 1 tank, 4.7ms\n",
      "image 74/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/992ddb9aa11e82ca.jpg: 480x640 1 tank, 4.9ms\n",
      "image 75/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/a3fba091de814cd2.jpg: 288x640 3 tanks, 88.3ms\n",
      "image 76/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/ab81bfcaa8526559.jpg: 416x640 3 tanks, 5.4ms\n",
      "image 77/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/ac15a022b6244819.jpg: 480x640 2 tanks, 5.2ms\n",
      "image 78/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/ad0e07536ba99aa6.jpg: 480x640 1 tank, 4.9ms\n",
      "image 79/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/b0ab66c440cfb524.jpg: 480x640 1 tank, 4.9ms\n",
      "image 80/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/b25c785757144169.jpg: 640x640 1 tank, 5.8ms\n",
      "image 81/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/b4d3572255f116e6.jpg: 448x640 1 tank, 5.3ms\n",
      "image 82/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/b515f23366c98cbe.jpg: 448x640 1 tank, 4.8ms\n",
      "image 83/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/b51a023007c0b8f6.jpg: 448x640 2 tanks, 4.8ms\n",
      "image 84/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/b85d846dbc861d1c.jpg: 448x640 2 tanks, 4.7ms\n",
      "image 85/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/c1291c3ec2076567.jpg: 480x640 1 tank, 5.2ms\n",
      "image 86/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/c2b4ce7016714764.jpg: 448x640 4 tanks, 5.3ms\n",
      "image 87/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/c3f871ae9e20dc0d.jpg: 512x640 1 tank, 5.3ms\n",
      "image 88/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/c410a8504a86474a.jpg: 512x640 2 tanks, 4.7ms\n",
      "image 89/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/c5c4c7a77bca9aca.jpg: 448x640 3 tanks, 5.0ms\n",
      "image 90/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/c5ed1732df8f8bb6.jpg: 640x640 5 tanks, 5.7ms\n",
      "image 91/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/c9ce63abf06e7fe4.jpg: 448x640 3 tanks, 5.0ms\n",
      "image 92/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/cbcf2e341f48101e.jpg: 480x640 1 tank, 5.3ms\n",
      "image 93/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/cc26bf58c1bb6ca4.jpg: 512x640 1 tank, 5.1ms\n",
      "image 94/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/cd3b04e8cf9e93e1.jpg: 640x480 (no detections), 5.2ms\n",
      "image 95/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/cd6470b726c59bf9.jpg: 480x640 1 tank, 5.2ms\n",
      "image 96/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/d029631302d99576.jpg: 448x640 1 tank, 5.1ms\n",
      "image 97/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/d339a4a95eb9b935.jpg: 480x640 4 tanks, 5.1ms\n",
      "image 98/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/d55965a9ea0eef56.jpg: 448x640 2 tanks, 5.2ms\n",
      "image 99/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/d6f6f54a316d2e78.jpg: 448x640 2 tanks, 4.7ms\n",
      "image 100/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/d83b54f0fbfd0db5.jpg: 448x640 1 tank, 4.8ms\n",
      "image 101/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/d88f60584459ac5f.jpg: 480x640 1 tank, 5.2ms\n",
      "image 102/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/d9b835b5f987eab5.jpg: 384x640 1 tank, 5.3ms\n",
      "image 103/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/da82539684a90087.jpg: 480x640 1 tank, 5.0ms\n",
      "image 104/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/dc65bdffd54bcf74.jpg: 544x640 1 tank, 5.3ms\n",
      "image 105/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/dc6e8ce4c73b58d6.jpg: 512x640 1 tank, 5.2ms\n",
      "image 106/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/dd94f9d7fdad41b7.jpg: 448x640 1 tank, 5.2ms\n",
      "image 107/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/de6c4a4ff9c9e17a.jpg: 416x640 1 tank, 5.1ms\n",
      "image 108/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/e2470664bdffd508.jpg: 448x640 1 tank, 4.9ms\n",
      "image 109/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/e8cb28a029fba249.jpg: 480x640 2 tanks, 5.1ms\n",
      "image 110/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/ebbf1cb5266bf5f0.jpg: 480x640 4 tanks, 4.6ms\n",
      "image 111/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/ebf36e85edfd6ba2.jpg: 480x640 1 tank, 5.0ms\n",
      "image 112/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/efadc02516eb6a50.jpg: 640x480 7 tanks, 5.2ms\n",
      "image 113/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/efde03f4a9d8005f.jpg: 480x640 1 tank, 5.0ms\n",
      "image 114/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/f41ac836abbc5bf5.jpg: 640x640 6 tanks, 5.7ms\n",
      "image 115/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/f782835183dd5cf8.jpg: 480x640 2 tanks, 5.1ms\n",
      "image 116/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/f864f0d987bb8092.jpg: 480x640 2 tanks, 4.7ms\n",
      "image 117/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/fb928a465c032c18.jpg: 448x640 1 tank, 5.0ms\n",
      "image 118/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/fc53af39f59eea7e.jpg: 448x640 4 tanks, 4.8ms\n",
      "image 119/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_1064.JPEG: 480x640 1 tank, 5.3ms\n",
      "image 120/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_11108.JPEG: 512x640 1 tank, 5.2ms\n",
      "image 121/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_11395.JPEG: 480x640 2 tanks, 5.1ms\n",
      "image 122/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_1158.JPEG: 480x640 1 tank, 4.8ms\n",
      "image 123/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_12401.JPEG: 416x640 1 tank, 5.1ms\n",
      "image 124/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_12568.JPEG: 448x640 1 tank, 4.9ms\n",
      "image 125/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_13621.JPEG: 640x448 1 tank, 4.9ms\n",
      "image 126/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_15233.JPEG: 480x640 1 tank, 5.1ms\n",
      "image 127/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_15378.JPEG: 480x640 1 tank, 4.7ms\n",
      "image 128/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_17200.JPEG: 448x640 1 tank, 4.9ms\n",
      "image 129/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_18598.JPEG: 480x640 1 tank, 5.1ms\n",
      "image 130/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_18754.JPEG: 416x640 1 tank, 5.2ms\n",
      "image 131/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_2015.JPEG: 512x640 1 tank, 4.9ms\n",
      "image 132/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_20645.JPEG: 480x640 1 tank, 5.0ms\n",
      "image 133/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_21017.JPEG: 480x640 2 tanks, 4.8ms\n",
      "image 134/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_21280.JPEG: 480x640 1 tank, 4.7ms\n",
      "image 135/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_21384.JPEG: 448x640 1 tank, 5.0ms\n",
      "image 136/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_2171.JPEG: 480x640 1 tank, 5.0ms\n",
      "image 137/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_23580.JPEG: 352x640 1 tank, 5.5ms\n",
      "image 138/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_24389.JPEG: 512x640 1 tank, 5.2ms\n",
      "image 139/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_2588.JPEG: 480x640 1 tank, 5.2ms\n",
      "image 140/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_26102.JPEG: 480x640 1 tank, 4.6ms\n",
      "image 141/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_26695.JPEG: 448x640 1 tank, 5.3ms\n",
      "image 142/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_29587.JPEG: 448x640 1 tank, 4.7ms\n",
      "image 143/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_29887.JPEG: 416x640 1 tank, 5.1ms\n",
      "image 144/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_29960.JPEG: 448x640 1 tank, 5.0ms\n",
      "image 145/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_31010.JPEG: 416x640 1 tank, 4.9ms\n",
      "image 146/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_31763.JPEG: 480x640 1 tank, 5.3ms\n",
      "image 147/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_32316.JPEG: 480x640 2 tanks, 4.8ms\n",
      "image 148/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_351.JPEG: 384x640 4 tanks, 5.1ms\n",
      "image 149/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_352.JPEG: 352x640 1 tank, 5.3ms\n",
      "image 150/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_5200.JPEG: 384x640 1 tank, 5.2ms\n",
      "image 151/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_5457.JPEG: 448x640 1 tank, 5.0ms\n",
      "image 152/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_622.JPEG: 448x640 1 tank, 4.7ms\n",
      "image 153/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_6534.JPEG: 352x640 1 tank, 5.1ms\n",
      "image 154/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_7113.JPEG: 480x640 1 tank, 5.0ms\n",
      "image 155/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_7506.JPEG: 640x512 1 tank, 88.3ms\n",
      "image 156/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_7725.JPEG: 480x640 1 tank, 5.2ms\n",
      "image 157/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_8351.JPEG: 480x640 1 tank, 5.0ms\n",
      "image 158/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_8704.JPEG: 320x640 1 tank, 5.3ms\n",
      "image 159/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_9218.JPEG: 480x640 1 tank, 5.0ms\n",
      "image 160/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_9260.JPEG: 640x480 1 tank, 5.1ms\n",
      "image 161/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_9414.JPEG: 448x640 1 tank, 4.9ms\n",
      "image 162/162 /home/ukemkata/workspace/adomvi2/notebooks/dataset/images/test/n04389033_9772.JPEG: 480x640 2 tanks, 5.1ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "160 labels saved to runs/detect/predict/labels\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from adomvi.yolo.yolo import predict\n",
    "\n",
    "best_model = Path() / \"runs/detect/train/weights/best.pt\"\n",
    "results = predict(best_model, source=dataset_dir / \"images/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef120f-376b-4218-ba8b-fdb5baad96c2",
   "metadata": {},
   "source": [
    "### Evaluate model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c3470a-653b-4552-a750-90238b94039e",
   "metadata": {},
   "source": [
    "We can first evaluate our model by loading the predictions in a Fiftyone dataset view of our test data. We select the images tagged as part of the test set in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d17c385-0934-41d4-952c-d25364780bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test split of the dataset\n",
    "test_view = dataset.match_tags(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ccadc7-987c-4aff-91ec-d44da3370dde",
   "metadata": {},
   "source": [
    "Then we can load the model predictions as fields of the images in our test view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ebffeaa-46b3-4f96-8e5b-db0531e8d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from adomvi.yolo.utils import add_yolo_detections\n",
    "\n",
    "prediction_field = \"yolov8\"\n",
    "predictions_dir = Path() / \"runs/detect/predict/labels\"\n",
    "add_yolo_detections(test_view, prediction_field=prediction_field, predictions_dir=predictions_dir, class_list=[\"tank\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6c727-fc8a-46f8-aef0-613ff77d7cc4",
   "metadata": {},
   "source": [
    "Now we can visualize these YOLOv8 model predictions on the samples in our dataset in the FiftyOne app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0da62f-30e6-4abf-a33b-68923ae40175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.open('http://localhost:5151/');"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d3a9f-aabe-43a5-b264-c0d935194b0e",
   "metadata": {},
   "source": [
    "Finally, we can evaluate our model's predictions and print the mAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f04724f1-42ff-424c-bc65-b8b7f76d097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 162/162 [486.5ms elapsed, 0s remaining, 333.0 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 162/162 [411.6ms elapsed, 0s remaining, 393.5 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "detection_results = test_view.evaluate_detections(\n",
    "    prediction_field, \n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    "    gt_field=\"ground_truth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba9326b5-b4fc-49d9-96ff-a21293e8bd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP = 0.5864953046579247\n"
     ]
    }
   ],
   "source": [
    "mAP = detection_results.mAP()\n",
    "print(f\"mAP = {mAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6818e918-1a61-4ac7-a403-e1e59b3fe9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        tank       0.83      0.84      0.84       245\n",
      "\n",
      "   micro avg       0.83      0.84      0.84       245\n",
      "   macro avg       0.83      0.84      0.84       245\n",
      "weighted avg       0.83      0.84      0.84       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detection_results.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72bc4ea-0293-4b6f-bb06-1f4997fec08c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
