{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16172d3-4aaf-4b8d-b9e1-b67f8322e01d",
   "metadata": {},
   "source": [
    "# Fine-tune a YOLOv8 detection model\n",
    "\n",
    "This notebook will train a [Yolov8](https://github.com/ultralytics/ultralytics) model for tank detection using publicly available annotated images of tanks.\n",
    "\n",
    "As the notebook will run the training with `PyTorch`, it is recommended to have GPUs available. If running in Google Colab, go to Edit > Notebook settings and select GPU hardware acceleration.\n",
    "\n",
    "This notebook expects that the dataset created in the notebook [01_Dataset](./01_Dataset.ipynb) has been saved to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d75f09-636f-4786-9d60-4a672c41c055",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78070ae-5cde-47ef-a394-4cbd74ad3cf7",
   "metadata": {},
   "source": [
    "To start, check GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc4c32f-48a1-453a-8526-63f79f504b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15382b1e-27bb-4614-b6e2-431ec0dd4967",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef8e715-e340-4187-a130-7c908114dd53",
   "metadata": {},
   "source": [
    "We'll first load the dataset created on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed58948a-0722-4abe-8bef-455309e652af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path() / \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031dba9b-53d3-4d09-8c4d-21f4cf15aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# The splits to load\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Load the dataset, using tags to mark the samples in each split\n",
    "dataset = fo.Dataset()\n",
    "for split in splits:\n",
    "    dataset.add_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        tags=split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec0a8e5-e73f-4ea3-b430-a0685292befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset, auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32557b80-147f-4628-963e-b0b4c41342f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0513e-7034-4949-b2f7-07423bfdfaca",
   "metadata": {},
   "source": [
    "### Train a YoloV8 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c987c05-848b-439e-8705-0735b100180f",
   "metadata": {},
   "source": [
    "We can now train a YoloV8 base model on our exported dataset. We use the `yolov8n.pt` (nano) model, which is the smallest, but larger models are available from ultralytics. Simply replace `yolov8n.pt` with the [right model](https://docs.ultralytics.com/models/yolov8/#key-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6999159-b029-4cd7-97ed-68b40311cbc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from adomvi.yolo.yolo import train\n",
    "\n",
    "results_train = train(\"yolov8m.pt\", data=dataset_dir / \"dataset.yaml\", batch=64, device=0)\n",
    "\n",
    "#Load the path of the training model results\n",
    "results_train_dir = Path(results_train.save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93614090-c4ea-4121-8e85-b85c5d49bec5",
   "metadata": {},
   "source": [
    "### Use the fine-tuned model to predict detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d024f-a83a-490f-80ff-020165dc8231",
   "metadata": {},
   "source": [
    "Once our model is trained, we can simply use it to predict detections on our test dataset. Simply pass the path to the best model weights and the directory containing the test images to the `predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712aefbd-757a-4184-8de6-4203a517f794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from adomvi.yolo.yolo import predict\n",
    "\n",
    "best_model = Path() / results_train_dir / \"weights/best.pt\"\n",
    "results_predict = predict(best_model, source=dataset_dir / \"images/test\")\n",
    "\n",
    "# Load the path of the prediction model results\n",
    "results_predict_dir = Path(results_predict[0].save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a61bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the best_model variable to a file\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef120f-376b-4218-ba8b-fdb5baad96c2",
   "metadata": {},
   "source": [
    "### Evaluate model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c3470a-653b-4552-a750-90238b94039e",
   "metadata": {},
   "source": [
    "We can first evaluate our model by loading the predictions in a Fiftyone dataset view of our test data. We select the images tagged as part of the test set in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17c385-0934-41d4-952c-d25364780bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test split of the dataset\n",
    "test_view = dataset.match_tags(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ccadc7-987c-4aff-91ec-d44da3370dde",
   "metadata": {},
   "source": [
    "Then we can load the model predictions as fields of the images in our test view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebffeaa-46b3-4f96-8e5b-db0531e8d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from adomvi.yolo.utils import add_yolo_detections\n",
    "\n",
    "prediction_field = \"yolov8\"\n",
    "predictions_dir = Path() / results_predict_dir / \"labels\"\n",
    "add_yolo_detections(test_view, prediction_field=prediction_field, predictions_dir=predictions_dir, class_list=[\"AFV\", \"APC\", \"MEV\", \"LAV\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6c727-fc8a-46f8-aef0-613ff77d7cc4",
   "metadata": {},
   "source": [
    "Now we can visualize these YOLOv8 model predictions on the samples in our dataset in the FiftyOne app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0da62f-30e6-4abf-a33b-68923ae40175",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d3a9f-aabe-43a5-b264-c0d935194b0e",
   "metadata": {},
   "source": [
    "Finally, we can evaluate our model's predictions and print the mAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04724f1-42ff-424c-bc65-b8b7f76d097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_results = test_view.evaluate_detections(\n",
    "    prediction_field, \n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    "    gt_field=\"ground_truth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9326b5-b4fc-49d9-96ff-a21293e8bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP = detection_results.mAP()\n",
    "print(f\"mAP = {mAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818e918-1a61-4ac7-a403-e1e59b3fe9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_results.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72bc4ea-0293-4b6f-bb06-1f4997fec08c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
